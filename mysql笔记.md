# SQL

### 通用语法

- SQL语句可以单行或多行书写，以分号结尾

- SQL语句可以使用空格/缩进来增强语句的可读性

- MySQL数据库的SQL语句不区分大小写，关键字建议使用大写

- 注释：

  - 单行注释：-- 注释内容 或 # 注释内容

  - 多行注释：/* 注释内容 */



### 数据类型

#### 数值类型

| 类型        | 大小   | 有符号(SIGNED)范围                                  | 无符号(UNSIGNED)范围                                   | 描述               |
| ----------- | ------ | --------------------------------------------------- | ------------------------------------------------------ | ------------------ |
| TINYINT     | 1byte  | (-128，127)                                         | (0，255)                                               | 小整数值           |
| SMALLINT    | 2bytes | (-32768，32767)                                     | (0，65535)                                             | 大整数值           |
| MEDIUMINT   | 3bytes | (-8388608，8388607)                                 | (0，16777215)                                          | 大整数值           |
| INT/INTEGER | 4bytes | (-2147483648，2147483647)                           | (0，4294967295)                                        | 大整数值           |
| BIGINT      | 8bytes | (-2^63，2^63-1)                                     | (0，2^64-1)                                            | 极大整数值         |
| FLOAT       | 4bytes | (-3.402823466 E+38，3.402823466351 E+38)            | 0 和 (1.175494351 E-38，3.402823466 E+38)              | 单精度浮点数       |
| DOUBLE      | 8bytes | (-1.7976931348623157E+308，1.7976931348623157E+308) | 0 和(2.2250738585072014E-308，1.7976931348623157E+308) | 双精度浮点数值     |
| DECIMAL     |        | 依赖于M(精度)和D(标度)的值                          | 依赖于M(精度)和D(标度)的值                             | 小数值(精确定点数) |



#### 字符串类型

| 类型       | 大小                  | 描述                         |
| ---------- | --------------------- | ---------------------------- |
| CHAR       | 0-255 bytes           | 定长字符串(需要指定长度)     |
| VARCHAR    | 0-65535 bytes         | 变长字符串(需要指定长度)     |
| TINYBLOB   | 0-255 bytes           | 不超过255个字符的二进制数据  |
| TINYTEXT   | 0-255 bytes           | 短文本字符串                 |
| BLOB       | 0-65 535 bytes        | 二进制形式的长文本数据       |
| TEXT       | 0-65 535 bytes        | 长文本数据                   |
| MEDIUMBLOB | 0-16 777 215 bytes    | 二进制形式的中等长度文本数据 |
| MEDIUMTEXT | 0-16 777 215 bytes    | 中等长度文本数据             |
| LONGBLOB   | 0-4 294 967 295 bytes | 二进制形式的极大文本数据     |
| LONGTEXT   | 0-4 294 967 295 bytes | 极大文本数据                 |



#### 日期时间类型

| 类型      | 大小 | 范围                                       | 格式                | 描述                     |
| --------- | ---- | ------------------------------------------ | ------------------- | ------------------------ |
| DATE      | 3    | 1000-01-01 至 9999-12-31                   | YYYY-MM-DD          | 日期值                   |
| TIME      | 3    | -838:59:59 至 838:59:59                    | HH:MM:SS            | 时间值或持续时间         |
| YEAR      | 1    | 1901 至 2155                               | YYYY                | 年份值                   |
| DATETIME  | 8    | 1000-01-01 00:00:00 至 9999-12-31 23:59:59 | YYYY-MM-DD HH:MM:SS | 混合日期和时间值         |
| TIMESTAMP | 4    | 1970-01-01 00:00:01 至 2038-01-19 03:14:07 | YYYY-MM-DD HH:MM:SS | 混合日期和时间值，时间戳 |



### 分类

SQL语句，根据其功能，主要分为四类：DDL、DML、DQL、DCL

| 分类 | 全称                       | 说明                                               |
| ---- | -------------------------- | -------------------------------------------------- |
| DDL  | Data Definition Language   | 数据定义语言，用来定义数据库对象(数据库，表，字段) |
| DML  | Data Manipulation Language | 数据操作语言，用来对数据库表中的数据进行增删改     |
| DQL  | Data Query Language        | 数据查询语言，用来查询数据库中表的记录             |
| DCL  | Data Control Language      | 数据控制语言，用来创建数据库用户、控制数据库的     |



#### DDL

##### 数据库操作

| 说明           | 指令                                                         |
| -------------- | ------------------------------------------------------------ |
| 查询所有数据库 | show databases;                                              |
| 查询当前数据库 | select database();                                           |
| 创建数据库     | create database [ if not exists ] 数据库名 [ default charset 字符集 ] [ collate 排序规则 ] ; |
| 删除数据库     | drop database [ if exists ] 数据库名;                        |
| 切换数据库     | use 数据库名;                                                |



##### 表操作-查询创建

| 说明                 | 指令                    |
| -------------------- | ----------------------- |
| 查询当前数据库所有表 | show tables;            |
| 查看指定表结构       | desc 表名;              |
| 查询指定表的建表语句 | show create table 表名; |
| 创建表结构           | 如下                    |

创建表结构

```mysql
CREATE TABLE 表名(
    字段1 字段1类型 [ COMMENT 字段1注释 ],
    字段2 字段2类型 [COMMENT 字段2注释 ],
    字段3 字段3类型 [COMMENT 字段3注释 ],
    ......
    字段n 字段n类型 [COMMENT 字段n注释 ]
) [ COMMENT 表注释 ] ;
```



##### 表操作-修改

| 说明                 | 指令                                                         |
| -------------------- | ------------------------------------------------------------ |
| 添加字段             | ALTER TABLE 表名 ADD 字段名 类型 (长度) [ COMMENT 注释 ] [ 约束 ]; |
| 修改数据类型         | ALTER TABLE 表名 MODIFY 字段名 新数据类型 (长度);            |
| 修改字段名和字段类型 | ALTER TABLE 表名 CHANGE 旧字段名 新字段名 类型 (长度) [ COMMENT 注释 ] [ 约束 ]; |
| 删除字段             | ALTER TABLE 表名 DROP 字段名;                                |
| 修改表名             | ALTER TABLE 表名 RENAME TO 新表名;                           |



##### 表操作-删除

| 说明                     | 指令                           |
| ------------------------ | ------------------------------ |
| 删除表                   | DROP TABLE [ IF EXISTS ] 表名; |
| 删除指定表, 并重新创建表 | TRUNCATE TABLE 表名;           |



#### DML

##### 添加数据

| 说明               | 指令                                                         |
| ------------------ | ------------------------------------------------------------ |
| 给指定字段添加数据 | INSERT INTO 表名 (字段名1, 字段名2, ...) VALUES (值1, 值2, ...); |
| 给全部字段添加数据 | INSERT INTO 表名 VALUES (值1, 值2, ...);                     |
| 批量添加数据       | INSERT INTO 表名 (字段名1, 字段名2, ...) VALUES (值1, 值2, ...), (值1, 值2, ...), (值1, 值2, ...);<br />INSERT INTO 表名 VALUES (值1, 值2, ...), (值1, 值2, ...), (值1, 值2, ...); |

注意事项:

- 插入数据时，指定的字段顺序需要与值的顺序是一一对应的
- 字符串和日期型数据应该包含在引号中
- 插入的数据大小，应该在字段的规定范围内



##### 修改数据

| 说明     | 指令                                                         |
| -------- | ------------------------------------------------------------ |
| 修改数据 | UPDATE 表名 SET 字段名1 = 值1 , 字段名2 = 值2 , .... [ WHERE 条件 ] ; |



##### 删除数据

| 说明     | 指令                              |
| -------- | --------------------------------- |
| 删除数据 | DELETE FROM 表名 [ WHERE 条件 ] ; |



#### DQL

```mysql
SELECT
	字段列表
FROM
	表名列表
WHERE
	条件列表
GROUP BY
	分组字段列表
HAVING
	分组后条件列表
ORDER BY
	排序字段列表
LIMIT
	分页参数
```



##### **基础查询**

| 说明         | 指令                                                         |
| ------------ | ------------------------------------------------------------ |
| 查询多个字段 | SELECT 字段1, 字段2, 字段3 ... FROM 表名 ;<br />SELECT * FROM 表名 ; |
| 字段设置别名 | SELECT 字段1 [ AS 别名1 ] , 字段2 [ AS 别名2 ] ... FROM 表名;<br />SELECT 字段1 [ 别名1 ] , 字段2 [ 别名2 ] ... FROM 表名; |
| 去除重复记录 | SELECT DISTINCT 字段列表 FROM 表名;                          |
|              |                                                              |
|              |                                                              |
|              |                                                              |



##### 条件查询

```mysql
SELECT 字段列表 FROM 表名 WHERE 条件列表 ;
```

| **比较运算符**      | 功能                                     |
| ------------------- | ---------------------------------------- |
| \>                  | 大于                                     |
| \>=                 | 大于等于                                 |
| <                   | 小于                                     |
| <=                  | 小于等于                                 |
| =                   | 等于                                     |
| <> 或 !=            | 不等于                                   |
| BETWEEN ... AND ... | 在某个范围之内(含最小、最大值)           |
| IN(...)             | 在in之后的列表中的值，多选一             |
| LIKE 占位符         | 模糊匹配(_匹配单个字符, %匹配任意个字符) |
| IS NULL             | 是NULL                                   |

| 逻辑运算符 | 功能                        |
| ---------- | --------------------------- |
| AND 或 &&  | 并且 (多个条件同时成立)     |
| OR 或 \|\| | 或者 (多个条件任意一个成立) |
| NOT 或 !   | 非 , 不是                   |



##### 聚合函数

- 将一列数据作为一个整体，进行纵向计算
- null值不参与所有聚合函数运算

```mysql
SELECT 聚合函数(字段列表) FROM 表名 ;
```

| 函数  | 功能     |
| ----- | -------- |
| count | 统计数量 |
| max   | 最大值   |
| min   | 最小值   |
| avg   | 平均值   |
| sum   | 求和     |



##### 分组查询

```mysql
SELECT 字段列表 FROM 表名 [ WHERE 条件 ] GROUP BY 分组字段名 [ HAVING 分组
后过滤条件 ];
```

where与having区别：

- 执行时机不同：where是分组之前进行过滤，不满足where条件，不参与分组；而having是分组

    之后对结果进行过滤

- 判断条件不同：where不能对聚合函数进行判断，而having可以

- 分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义

- 执行顺序: where > 聚合函数 > having 

- 支持多字段分组, 具体语法为 : group by columnA,columnB

**示例**

```mysql
# 查询年龄小于45的员工 , 并根据工作地址分组 , 获取员工数量大于等于3的工作地址
select workaddress, count(*) address_count from emp where age < 45 group by
workaddress having address_count >= 3;
```



##### 排序查询

```mysql
SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1 , 字段2 排序方式2 ;
```

排序方式：

- ASC : 升序(默认值)

- DESC: 降序



##### 分页查询

```mysql
SELECT 字段列表 FROM 表名 LIMIT 起始索引, 查询记录数 ;
```

- 起始索引从0开始，起始索引 = （查询页码 - 1）* 每页显示记录数
- 分页查询是数据库的方言，不同的数据库有不同的实现，MySQL中是LIMIT
- 如果查询的是第一页数据，起始索引可以省略，直接简写为 limit 10



##### 执行顺序

![image-20250416140423778](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250416140423778.png)



#### DCL

##### 管理用户

| 说明         | 指令                                                         |
| ------------ | ------------------------------------------------------------ |
| 查询用户     | select * from mysql.user;                                    |
| 创建用户     | CREATE USER '用户名'@'主机名' IDENTIFIED BY '密码';          |
| 修改用户密码 | ALTER USER '用户名'@'主机名' IDENTIFIED WITH mysql_native_password BY '新密码' ; |
| 删除用户     | DROP USER '用户名'@'主机名' ;                                |

注意事项:

- 在MySQL中需要通过用户名@主机名的方式，来唯一标识一个用户
- 主机名可以使用 % 通配
- 这类SQL开发人员操作的比较少，主要是DBA（ Database Administrator 数据库管理员）使用
- 主机名指定数据库在哪能访问



##### 权限控制

| 权限                | 说明               |
| ------------------- | ------------------ |
| ALL, ALL PRIVILEGES | 所有权限           |
| SELECT              | 查询数据           |
| INSERT              | 插入数据           |
| UPDATE              | 修改数据           |
| DELETE              | 删除数据           |
| ALTER               | 修改表             |
| DROP                | 删除数据库/表/视图 |
| CREATE              | 创建数据库/表      |

| 说明     | 指令                                                     |
| -------- | -------------------------------------------------------- |
| 查询权限 | SHOW GRANTS FOR '用户名'@'主机名' ;                      |
| 授予权限 | GRANT 权限列表 ON 数据库名.表名 TO '用户名'@'主机名';    |
| 撤销权限 | REVOKE 权限列表 ON 数据库名.表名 FROM '用户名'@'主机名'; |

注意事项：

- 多个权限之间，使用逗号分隔
- 授权时， 数据库名和表名可以使用 * 进行通配，代表所有



# 函数

### 字符串函数

| 函数                     | 功能                                                      |
| ------------------------ | --------------------------------------------------------- |
| CONCAT(S1,S2,...Sn)      | 字符串拼接，将S1，S2，... Sn拼接成一个字符串              |
| LOWER(str)               | 将字符串str全部转为小写                                   |
| UPPER(str)               | 将字符串str全部转为大写                                   |
| LPAD(str,n,pad)          | 左填充，用字符串pad对str的左边进行填充，达到n个字符串长度 |
| RPAD(str,n,pad)          | 右填充，用字符串pad对str的右边进行填充，达到n个字符串长度 |
| TRIM(str)                | 去掉字符串头部和尾部的空格                                |
| SUBSTRING(str,start,len) | 返回从字符串str从start位置起的len个长度的字符串           |



### 数值函数

| 函数       | 功能                               |
| ---------- | ---------------------------------- |
| CEIL(x)    | 向上取整                           |
| FLOOR(x)   | 向下取整                           |
| MOD(x,y)   | 返回x/y的模                        |
| RAND()     | 返回0~1内的随机数                  |
| ROUND(x,y) | 求参数x的四舍五入的值，保留y位小数 |



### 日期函数

| 函数                         | 功能                                              |
| ---------------------------- | ------------------------------------------------- |
| CURDATE()                    | 返回当前日期                                      |
| CURTIME()                    | 返回当前时间                                      |
| NOW()                        | 返回当前日期和时间                                |
| YEAR(date)                   | 获取指定date的年份                                |
| MONTH(date)                  | 获取指定date的月份                                |
| DAY(date)                    | 获取指定date的日期                                |
| DATE_ADD(date, INTERVAL expr | 返回一个日期/时间值加上一个时间间隔expr后的时间值 |
| DATEDIFF(date1,date2)        | 返回起始时间date1 和 结束时间date2之间的天数      |



### 流程函数

| 函数                                                         | 功能                                                      |
| ------------------------------------------------------------ | --------------------------------------------------------- |
| IF(value , t , f)                                            | 如果value为true，则返回t，否则返回f                       |
| IFNULL(value1 , value2)                                      | 如果value1不为空，返回value1，否则返回value2              |
| CASE WHEN [ val1 ] THEN [res1] ...ELSE [ default ] END       | 如果val1为true，返回res1，... 否则返回default默认值       |
| CASE [ expr ] WHEN [ val1 ] THEN [res1] ... ELSE [ default ] END | 如果expr的值等于val1，返回res1，... 否则返回default默认值 |



# 约束

### 概念

概念：约束是作用于表中字段上的规则，用于限制存储在表中的数据

目的：保证数据库中数据的正确、有效性和完整性

| 约束                     | 描述                                                     | 关键字      |
| ------------------------ | -------------------------------------------------------- | ----------- |
| 非空约束                 | 限制该字段的数据不能为null                               | NOT NULL    |
| 唯一约束                 | 保证该字段的所有数据都是唯一、不重复的                   | UNIQUE      |
| 主键约束                 | 主键是一行数据的唯一标识，要求非空且唯一                 | PRIMARY KEY |
| 默认约束                 | 保存数据时，如果未指定该字段的值，则采用默认值           | DEFAULT     |
| 检查约束(8.0.16版本之后) | 保证字段值满足某一个条件                                 | CHECK       |
| 外键约束                 | 用来让两张表的数据之间建立连接，保证数据的一致性和完整性 | FOREIGN KEY |



### 外键约束

用来让两张表的数据之间建立连接，从而保证数据的一致性和完整性



#### 添加外键

```mysql
CREATE TABLE 表名(
	字段名 数据类型,
	...
	[CONSTRAINT] [外键名称] FOREIGN KEY (外键字段名) REFERENCES 主表 (主表列名)
);

ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段名) REFERENCES 主表 (主表列名) ;
```



####  删除外键

```mysql
ALTER TABLE 表名 DROP FOREIGN KEY 外键名称;
```



### 删除/更新行为

添加了外键之后，再删除父表数据时产生的约束行为，我们就称为删除/更新行为。具体的删除/更新行

为有以下几种:

| 行为        | 说明                                                         |
| ----------- | ------------------------------------------------------------ |
| NO ACTION   | 当在父表中删除/更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除/更新。 (与 RESTRICT 一致) 默认行为 |
| RESTRICT    | 当在父表中删除/更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除/更新。 (与 NO ACTION 一致) 默认行为 |
| CASCADE     | 当在父表中删除/更新对应记录时，首先检查该记录是否有对应外键，如果有，则也删除/更新外键在子表中的记录。 |
| SET NULL    | 当在父表中删除对应记录时，首先检查该记录是否有对应外键，如果有则设置子表中该外键值为null（这就要求该外键允许取null）。 |
| SET DEFAULT | 父表有变更时，子表将外键列设置成一个默认的值 (Innodb不支持)  |



**语法**

```mysql
ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段) REFERENCES 主表名 (主表字段名) ON UPDATE CASCADE ON DELETE CASCADE;
```



# 多表查询

### 内连接

![image-20250416142114231](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250416142114231.png)

**隐式内连接**

```mysql
SELECT 字段列表 FROM 表1 , 表2 WHERE 条件 ... ;
```

**显式内连接**

```mysql
SELECT 字段列表 FROM 表1 [ INNER ] JOIN 表2 ON 连接条件 ... ;
```

**注意**

一旦为表起了别名，就不能再使用表名来指定对应的字段了，此时只能够使用别名来指定字

段



### 外连接

![image-20250416142255758](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250416142255758.png)

**左外连接**

```mysql
SELECT 字段列表 FROM 表1 LEFT [ OUTER ] JOIN 表2 ON 条件 ... ;
```

**右外连接**

```mysql
SELECT 字段列表 FROM 表1 RIGHT [ OUTER ] JOIN 表2 ON 条件 ... ;
```



### 自连接

- 自连接查询（可以是内连接查询、也可以是外连接查询），顾名思义，就是自己连接自己，也就是把一张表连接查询多次
- 在自连接查询中，必须要为表起别名，要不然我们不清楚所指定的条件、返回的字段，到底是哪一张表的字段

```mysql
SELECT 字段列表 FROM 表A 别名A JOIN 表A 别名B ON 条件 ... ;
```



### 联合查询

对于union查询，就是把多次查询的结果合并起来，形成一个新的查询结果集

```mysql
SELECT 字段列表 FROM 表A ...
UNION [ ALL ]
SELECT 字段列表 FROM 表B ....;
```

对于联合查询的多张表的列数必须保持一致，字段类型也需要保持一致。

union all 会将全部的数据直接合并在一起，union 会对合并之后的数据去重



### 子查询

SQL语句中嵌套SELECT语句，称为嵌套查询，又称子查询

```mysql
SELECT * FROM t1 WHERE column1 = ( SELECT column1 FROM t2 );
```

根据子查询结果不同，分为：

- 标量子查询（子查询结果为单个值）
- 列子查询(子查询结果为一列)
- 行子查询(子查询结果为一行)
- 表子查询(子查询结果为多行多列)



#### 标量子查询

子查询返回的结果是单个值（数字、字符串、日期等），最简单的形式，这种子查询称为标量子查询。

常用的操作符：= <> > >= < <=



#### 列子查询

子查询返回的结果是一列（可以是多行），这种子查询称为列子查询。

常用的操作符：IN 、NOT IN 、 ANY 、SOME 、 ALL

| 操作符 | 描述                                   |
| ------ | -------------------------------------- |
| IN     | 在指定的集合范围之内，多选一           |
| NOT IN | 不在指定的集合范围之内                 |
| ANY    | 子查询返回列表中，有任意一个满足即可   |
| SOME   | 与ANY等同，使用SOME的地方都可以使用ANY |
| ALL    | 子查询返回列表的所有值都必须满足       |



#### 行子查询

子查询返回的结果是一行（可以是多列），这种子查询称为行子查询。

常用的操作符：= 、<> 、IN 、NOT IN



#### 表子查询

子查询返回的结果是多行多列，这种子查询称为表子查询。

常用的操作符：IN



# 事务

- 事务是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败
- 默认MySQL的事务是自动提交的，也就是说，当执行完一条DML语句时，MySQL会立即隐式的提交事务



### 控制事务

**查看/设置事务提交方式**

```mysql
SELECT @@autocommit ;
SET @@autocommit = 0 ;
```

**提交事务**

```mysql
COMMIT;
```

**回滚事务**

```mysql
ROLLBACK;
```

上述的这种方式，我们是修改了事务的自动提交行为, 把默认的自动提交修改为了手动提交, 此时我们执行的DML语句都不会提交, 需要手动的执行commit进行提交



**开启事务**

```mysql
START TRANSACTION 或 BEGIN ;
```

**提交事务**

```mysql
COMMIT;
```

**回滚事务**

```mysql
ROLLBACK;
```



### 事务四大特性

- 原子性（Atomicity）：事务是不可分割的最小操作单元，要么全部成功，要么全部失败
- 一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态
- 隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行
- 持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的

上述就是事务的四大特性，简称ACID



### 并发事务问题

#### 脏读

一个事务读到另外一个事务还没有提交的数据

![image-20250416143418510](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250416143418510.png)



#### 不可重复读

一个事务先后读取同一条记录，但两次读取的数据不同，称之为不可重复读

![image-20250416143455165](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250416143455165.png)



#### 幻读

一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了 "幻影"

![image-20250416143615557](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250416143615557.png)



### 事务隔离级别

为了解决并发事务所引发的问题，在数据库中引入了事务隔离级别。主要有以下几种：

| 隔离级别              | 脏读（是否出现） | 不可重复读 | 幻读 |
| --------------------- | ---------------- | ---------- | ---- |
| Read uncommitted      | √                | √          | √    |
| Read committed        | ×                | √          | √    |
| Repeatable Read(默认) | ×                | ×          | √    |
| Serializable          | ×                | ×          | ×    |



| 操作             | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| 查看事务隔离级别 | SELECT @@TRANSACTION_ISOLATION;                              |
| 设置事务隔离级别 | SET [ SESSION \| GLOBAL ] TRANSACTION ISOLATION LEVEL { READ UNCOMMITTED \| READ COMMITTED |

事务隔离级别越高，数据越安全，但是性能越低



**不同隔离级别下的锁行为差异**

| 隔离级别                      | 加锁情况                                                     |
| ----------------------------- | ------------------------------------------------------------ |
| READ UNCOMMITTED              | 几乎不加锁（性能最高，但会有脏读问题）                       |
| READ COMMITTED                | 只对读取的行加记录锁（不加间隙锁）<br />语句执行期间持有锁，语句结束即释放（不等到事务结束） |
| REPEATABLE READ（InnoDB默认） | 对读取的行加记录锁<br />对扫描的范围加间隙锁（防止幻读）<br />事务期间持续持有锁 |
| SERIALIZABLE                  | 所有普通SELECT自动转为`SELECT ... LOCK IN SHARE MODE`<br />加锁范围最大，并发度最低 |



# 存储引擎

### 体系结构

![image-20250417095526645](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417095526645.png)

**连接层**

最上层是一些客户端和链接服务，包含本地sock 通信和大多数基于客户端/服务端工具实现的类似于

TCP/IP的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程

池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务

器也会为安全接入的每个客户端验证它所具有的操作权限

**服务层**

第二层架构主要完成大多数的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化，部

分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如过程、函数等。在该层，服务器会解

析查询并创建相应的内部解析树，并对其完成相应的优化如确定表的查询的顺序，是否利用索引等，

最后生成相应的执行操作。如果是select语句，服务器还会查询内部的缓存，如果缓存空间足够大，

这样在解决大量读操作的环境中能够很好的提升系统的性能

**引擎层**

存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API和存储引擎进行通

信。不同的存储引擎具有不同的功能，这样我们可以根据自己的需要，来选取合适的存储引擎。数据库

中的索引是在存储引擎层实现的

**存储层**

数据存储层， 主要是将数据(如: redolog、undolog、数据、索引、二进制日志、错误日志、查询

日志、慢查询日志等)存储在文件系统之上，并完成与存储引擎的交互



### 介绍

存储引擎就是==存储数据、建立索引、更新/查询数据等技术的实现方式== 。存储引擎是基于表的，而不是

基于库的，所以存储引擎也可被称为表类型。我们可以在创建表的时候，来指定选择的存储引擎，如果

没有指定将自动选择默认的存储引擎



**建表时指定存储引擎**

```mysql
CREATE TABLE 表名(
	字段1 字段1类型 [ COMMENT 字段1注释 ] ,
	......
	字段n 字段n类型 [COMMENT 字段n注释 ]
) ENGINE = INNODB [ COMMENT 表注释 ] ;
```



**查询当前数据库支持的存储引擎**

```mysql
show engines;
```



### 特点

#### InnoDB

InnoDB是一种兼顾高可靠性和高性能的通用存储引擎，在 MySQL 5.5 之后，InnoDB是默认的

MySQL 存储引擎



**特点**

- DML操作遵循ACID模型，支持事务；

- 行级锁，提高并发访问性能；

- 支持外键FOREIGN KEY约束，保证数据的完整性和正确性；



**文件**

xxx.ibd：xxx代表的是表名，innoDB引擎的每张表都会对应这样一个表空间文件，存储该表的表结

构（frm-早期的 、sdi-新版的）、数据和索引



**逻辑存储结构**

![image-20250417101939331](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417101939331.png)

- 表空间 : InnoDB存储引擎逻辑结构的最高层，ibd文件其实就是表空间文件，在表空间中可以包含多个Segment段
- 段 : 表空间是由各个段组成的， 常见的段有数据段、索引段、回滚段等。InnoDB中对于段的管理，都是引擎自身完成，不需要人为对其控制，一个段中包含多个区
- 区 : 区是表空间的单元结构，每个区的大小为1M。 默认情况下， InnoDB存储引擎页大小为16K， 即一个区中一共有64个连续的页
- 页 : 页是组成区的最小单元，**页也是InnoDB存储引擎磁盘管理的最小单元**，每个页的大小默认为 16KB。为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区
- 行 : InnoDB 存储引擎是面向行的，也就是说数据是按行进行存放的，在每一行中除了定义表时所指定的字段以外，还包含两个隐藏字段



#### MyISA

MyISAM是MySQL早期的默认存储引擎



**特点**

- 不支持事务，不支持外键

- 支持表锁，不支持行锁

- 访问速度快



**文件**

- xxx.sdi：存储表结构信息

- xxx.MYD: 存储数据

- xxx.MYI: 存储索引



#### Memory

Memory引擎的表数据时存储在内存中的，由于受到硬件问题、或断电问题的影响，只能将这些表作为

临时表或缓存使用



**特点**

- 内存存放

-  hash索引（默认）



**文件**

xxx.sdi：存储表结构信息



#### 区别及特点

| 特点         | InnoDB           | MyISAM | Memory |
| ------------ | ---------------- | ------ | ------ |
| 存储限制     | 64TB             | 有限制 | 有限制 |
| 事务安全     | 支持             | \-     | \-     |
| 锁机制       | 行锁             | 表锁   | 表锁   |
| B+tree索引   | 支持             | 支持   | 支持   |
| Hash索引     | \-               | \-     | 支持   |
| 全文索引     | 支持(5.6版本之后 | 支持   | \-     |
| 空间使用     | 高               | 低     | N/A    |
| 内存使用     | 高               | 低     | 中等   |
| 批量插入速度 | 低               | 高     | 高     |
| 支持外键     | 支持             | \-     | \-     |



### 如何选择

在选择存储引擎时，应该根据应用系统的特点选择合适的存储引擎。对于复杂的应用系统，还可以根据

实际情况选择多种存储引擎进行组合

- InnoDB: 是Mysql的默认存储引擎，支持事务、外键。如果应用对事务的完整性有比较高的要求，在并发条件下求数据的一致性，数据操作除了插入和查询之外，还包含很多的更新、删除操作，那么InnoDB存储引擎是比较合的选择
- MyISAM ： 如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不是很高，那么选择这个存储引擎是非常合适的
- MEMORY：将所有数据保存在内存中，访问速度快，通常用于临时表及缓存。MEMORY的缺陷就是对表的大小有限制，太大的表无法缓存在内存中，而且无法保障数据的安全性



# 索引

### 概述

==索引（index）是帮助MySQL高效获取数据的数据结构(有序)==。在数据之外，数据库系统还维护着满足

特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据， 这样就可以在这些数据结构

上实现高级查找算法，这种数据结构就是索引

| 优势                                                        | 劣势                                                         |
| ----------------------------------------------------------- | ------------------------------------------------------------ |
| 提高数据检索的效率，降低数据库的IO成本                      | 索引列也是要占用空间的                                       |
| 通过索引列对数据进行排序，降低数据排序的成本，降低CPU的消耗 | 索引大大提高了查询效率，同时却也降低更新表的速度，如对表进行INSERT、UPDATE、DELETE时，效率降低 |



### 结构

MySQL的索引是在存储引擎层实现的，不同的存储引擎有不同的索引结构，主要包含以下几种：

| 索引结构            | 描述                                                         |
| ------------------- | ------------------------------------------------------------ |
| B+Tree索引          | 最常见的索引类型，大部分引擎都支持 B+ 树索引                 |
| Hash索引            | 底层数据结构是用哈希表实现的, 只有精确匹配索引列的查询才有效, 不支持范围查询 |
| R-tree(空间索引）   | 空间索引是MyISAM引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少 |
| Full-text(全文索引) | 是一种通过建立倒排索引,快速匹配文档的方式。类似于Lucene,Solr,ES |

不同的存储引擎对于索引结构的支持情况：

| 索引        | InnoDB          | MyISAM | Memory |
| ----------- | --------------- | ------ | ------ |
| B+tree索引  | 支持            | 支持   | 支持   |
| Hash 索引   | 不支持          | 不支持 | 支持   |
| R-tree 索引 | 不支持          | 支持   | 不支持 |
| Full-text   | 5.6版本之后支持 | 支持   | 不支持 |

> [!NOTE]
>
> 我们平常所说的索引，如果没有特别指明，都是指B+树结构组织的索引



#### 二叉树

假如说MySQL的索引结构采用二叉树的数据结构，比较理想的结构如下：

![image-20250417110404596](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417110404596.png)

如果主键是顺序插入的，则会形成一个单向链表，结构如下：

![image-20250417110427896](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417110427896.png)

所以，如果选择二叉树作为索引结构，会存在以下缺点：

- 顺序插入时，会形成一个链表，查询性能大大降低。

- 大数据量情况下，层级较深，检索速度慢。



红黑树是一颗自平衡二叉树，那这样即使是顺序插入数

据，最终形成的数据结构也是一颗平衡的二叉树,结构如下:

![image-20250417110531367](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417110531367.png)

但是，即使如此，由于红黑树也是一颗二叉树，所以也会存在一个缺点：大数据量情况下，层级较深，检索速度慢



#### B-Tree

B-Tree，B树是一种多叉路衡查找树，相对于二叉树，B树每个节点可以有多个分支，即多叉。

以一颗最大度数（max-degree）为5(5阶)的b-tree为例，那这个B树每个节点最多存储4个key，5

个指针：

![image-20250417110653523](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417110653523.png)

> [!NOTE]
>
> 树的度数指的是一个节点的子节点个数

特点：

- 5阶的B树，每一个节点最多存储4个key，对应5个指针

- 一旦节点存储的key数量到达5，就会裂变，中间元素向上分裂

- 在B树中，非叶子节点和叶子节点都会存放数据



#### B+Tree

B+Tree是B-Tree的变种，我们以一颗最大度数（max-degree）为4（4阶）的b+tree为例，来看一

下其结构示意图：

![image-20250417110926245](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417110926245.png)

我们可以看到，两部分：

- 绿色框框起来的部分，是索引部分，仅仅起到索引数据的作用，不存储数据

- 红色框框起来的部分，是数据存储部分，在其叶子节点中要存储具体的数据



B+Tree 与 B-Tree相比，主要有以下三点区别：

- 所有的数据都会出现在叶子节点

- 叶子节点形成一个单向链表

- 非叶子节点仅仅起到索引数据作用，具体的数据都是在叶子节点存放的



上述我们所看到的结构是标准的B+Tree的数据结构，接下来，我们再来看看MySQL中优化之后的

B+Tree：

MySQL索引数据结构对经典的B+Tree进行了优化。在原B+Tree的基础上，增加一个指向相邻叶子节点

的链表指针，就形成了带有顺序指针的B+Tree，提高区间访问的性能，利于排序

![image-20250417111303809](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417111303809.png)



**说明**

假设有一个表index_demo，表中有2个INT类型的列，1个CHAR(1)类型的列，c1列为主键：

```sql
CREATE TABLE index_demo(c1 INT,c2 INT,c3 CHAR(1),PRIMARY KEY(c1)) ;
```



index_demo表的简化的行格式示意图如下：

![image-20250508161116857](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250508161116857.png)

我们只在示意图里展示记录的这几个部分：

- `record_type：`表示记录的类型， 0是普通记录、 2是最小记录、 3 是最大记录、1是B+树非叶子节点记录
- `next_record：`表示下一条记录的相对位置，我们用箭头来表明下一条记录
- `各个列的值：`这里只记录在 index_demo 表中的三个列，分别是 c1 、 c2 和 c3 
- `其他信息：`除了上述3种信息以外的所有信息，包括其他隐藏列的值以及记录的额外信息



将`其他信息`项暂时去掉并把它竖起来的效果就是这样：

![image-20250508161201993](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250508161201993.png)

把一些记录放到页里的示意图就是（这里一页就是一个磁盘块，代表一次IO）：

![image-20250508161230469](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250508161230469.png)

最终如下图：

![image-20250508161447214](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250508161447214.png)



#### Hash

哈希索引就是采用一定的hash算法，将键值换算成新的hash值，映射到对应的槽位上，然后存储在

hash表中

![image-20250417112958465](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417112958465.png)

如果两个(或多个)键值，映射到一个相同的槽位上，他们就产生了hash冲突（也称为hash碰撞），可

以通过链表来解决：

![image-20250417113013106](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417113013106.png)

特点：

- Hash索引只能用于对等比较(=，in)，不支持范围查询（between，>，< ，...）

- 无法利用索引完成排序操作

- 查询效率高，通常(不存在hash冲突的情况)只需要一次检索就可以了，效率通常要高于B+tree索



在MySQL中，支持hash索引的是Memory存储引擎。 而InnoDB中具有自适应hash功能，hash索引是

InnoDB存储引擎根据B+Tree索引在指定条件下自动构建的



> [!IMPORTANT]
>
> 为什么InnoDB存储引擎选择使用B+tree索引结构？
>
> - 相对于二叉树，层级更少，搜索效率高
> - 对于B-tree，无论是叶子节点还是非叶子节点，都会保存数据，这样导致一页中存储的键值减少，指针跟着减少，要同样保存大量数据，只能增加树的高度，导致性能降低
> - 相对Hash索引，B+tree支持范围匹配及排序操作



### 分类

在MySQL数据库，将索引的具体类型主要分为以下几类：主键索引、唯一索引、常规索引、全文索引

| 分类     | 含义                                                 | 特点                     | 关键字   |
| -------- | ---------------------------------------------------- | ------------------------ | -------- |
| 主键索引 | 针对于表中主键创建的索引                             | 默认自动创建, 只能有一个 | PRIMARY  |
| 唯一索引 | 避免同一个表中某数据列中的值重复                     | 可以有多个               | UNIQUE   |
| 常规索引 | 快速定位特定数据                                     | 可以有多个               |          |
| 全文索引 | 全文索引查找的是文本中的关键词，而不是比较索引中的值 | 可以有多个               | FULLTEXT |



**聚集索引&二级索引**

在InnoDB存储引擎中，根据索引的==存储形式==，又可以分为以下两种：

| 分类                     | 含义                                                       | 特点                |
| ------------------------ | ---------------------------------------------------------- | ------------------- |
| 聚集索引(ClusteredIndex) | 将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据 | 必须有,而且只有一个 |
| 二级索引(SecondaryIndex) | 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 | 可以存在多个        |

聚集索引选取规则:

- 如果存在主键，主键索引就是聚集索引
- 如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引
- 如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引



聚集索引和二级索引的具体结构如下：

![image-20250417122905676](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417122905676.png)

- 聚集索引的叶子节点下挂的是这一行的数据
- 二级索引的叶子节点下挂的是该字段值对应的主键值



执行如下的SQL语句时，查找过程：

![image-20250417122914537](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417122914537.png)

具体过程如下:

1. 由于是根据name字段进行查询，所以先根据name='Arm'到name字段的二级索引中进行匹配查找。但是在二级索引中只能查找到 Arm 对应的主键值 10
2. 由于查询返回的数据是*，所以此时，还需要根据主键值10，到聚集索引中查找10对应的记录，最终找到10对应的行row
3. 最终拿到这一行的数据，直接返回即可



> [!NOTE]
>
> 回表查询： 这种先到二级索引中查找数据，找到主键值，然后再到聚集索引中根据主键值，获取
>
> 数据的方式，就称之为回表查询



### 语法

| 说明     | 指令                                                         |
| -------- | ------------------------------------------------------------ |
| 创建索引 | CREATE [ UNIQUE \| FULLTEXT ] INDEX index_name ON table_name (index_col_name,... ) ; |
| 查看索引 | SHOW INDEX FROM table_name ;                                 |
| 删除索引 | DROP INDEX index_name ON table_name ;                        |



### 性能分析

#### SQL执行频率

```mysql
show [session|global] status LIKE 'Com_______';
```

| 字段                     | 说明     |
| ------------------------ | -------- |
| Com_delete               | 删除次数 |
| Com_insert               | 插入次数 |
| Com_select               | 查询次数 |
| Com_update               | 更新次数 |
| Com\_\_\_\_\_\_\_（7个） | 查询所有 |

通过上述指令，我们可以查看到当前数据库到底是以查询为主，还是以增删改为主，从而为数据

库优化提供参考依据。 如果是以增删改为主，我们可以考虑不对其进行索引的优化。 如果是以

查询为主，那么就要考虑对数据库的索引进行优化了



#### 慢查询日志

慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有

SQL语句的日志

MySQL的慢查询日志默认没有开启，我们可以查看一下系统变量 slow_query_log：

```mysql
show variables like 'slow_query_log';
```

如果要开启慢查询日志，需要在MySQL的配置文件中配置如下信息：

```
# 开启MySQL慢日志查询开关
slow_query_log=1
# 设置慢日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志
long_query_time=2
```

配置完毕之后，重启MySQL服务，查看慢日志文件中记录的信息/var/lib/mysql/\<hostname\>-slow.log



#### profile详情

show profiles 能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。通过have_profiling

参数，能够看到当前MySQL是否支持profile操作：

```mysql
SELECT @@have_profiling;
```

查看是否打开：

```mysql
SELECT @@profiling;
```

默认是关闭的，可通过下面的指令打开

```mysql
SET profiling = 1;
```



执行一系列的业务SQL的操作，然后通过如下指令查看指令的执行耗时：

```mysql
-- 查看每一条SQL的耗时基本情况
show profiles;

-- 查看指定query_id的SQL语句各个阶段的耗时情况
show profile for query query_id;

-- 查看指定query_id的SQL语句CPU的使用情况
show profile cpu for query query_id;
```



#### **explain**

EXPLAIN 或者 DESC命令获取 MySQL 如何执行 SELECT 语句的信息，包括在 SELECT 语句执行过程中表如何连接和连接的顺序:

```mysql
-- 直接在select语句之前加上关键字 explain / desc
EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件;
```

| 字段         | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| id           | select查询的序列号，表示查询中执行select子句或者是操作表的顺序(id相同，执行顺序从上到下；id不同，值越大，越先执行) |
| select_type  | 表示 SELECT 的类型，常见的取值有 SIMPLE（简单表，即不使用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION 中的第二个或者后面的查询语句）、SUBQUERY（SELECT/WHERE之后包含了子查询）等 |
| type         | 表示连接类型，性能由好到差的连接类型为NULL、system、const、eq_ref、ref、range、 index、all |
| possible_key | 显示可能应用在这张表上的索引，一个或多个                     |
| key          | 实际使用的索引，如果为NULL，则没有使用索引                   |
| key_len      | 表示索引中使用的字节数， 该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下， 长度越短越好 |
| rows         | MySQL认为必须要执行查询的行数，在innodb引擎的表中，是一个估计值，可能并不总是准确的 |
| filtered     | 表示返回结果的行数占需读取行数的百分比，filtered 的值越大越好 |
| extra        | [覆盖索引](####覆盖索引)                                     |



### 索引使用

#### 最左前缀法则

如果索引了多列（联合索引），要遵守最左前缀法则。最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳跃某一列，索引将会部分失效(后面的字段索引失效)



#### 范围查询

- 联合索引中，出现范围查询(>,<)，范围查询右侧的列索引失效
- 当范围查询使用>= 或 <= 时，走联合索引
- 在业务允许的情况下，尽可能的使用类似于 >= 或 <= 这类的范围查询，而避免使用 > 或 <



#### 索引失效情况

| 情况           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| 索引列运算     | 不要在索引列上进行函数运算操作， 索引将失效                  |
| 字符串不加引号 | 字符串类型字段使用时，不加引号，索引将失效                   |
| 模糊查询       | 如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效 |
| or连接条件     | 用or分割开的条件， 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会用到；左右两侧字段都有索引时，索引才会生效 |
| 数据分布影响   | 如下                                                         |



**数据分布影响**

- 如果MySQL评估使用索引比全表更慢，则不使用索引

- 有时相同的SQL语句，只是传入的字段值不同，最终的执行计划也完全不一样

- 是因为MySQL在查询时，会评估使用索引的效率与走全表扫描的效率，如果走全表扫描更快，则放弃索引，走全表扫描。 因为索引是用来索引少量数据的，如果通过索引查询返回大批量的数据，则还不如走全表扫描来的快，此时索引就会失效



#### SQL提示

SQL提示，是优化数据库的一个重要手段，简单来说，就是在SQL语句中加入一些人为的提示来达到优

化操作的目的：

use index ： 建议MySQL使用哪一个索引完成此次查询（仅仅是建议，mysql内部还会再次进

行评估）

```mysql
explain select * from tb_user use index(idx_user_pro) where profession = '软件工程';
```

ignore index ： 忽略指定的索引

```mysql
explain select * from tb_user ignore index(idx_user_pro) where profession = '软件工程';
```

orce index ： 强制使用索引

```mysql
explain select * from tb_user force index(idx_user_pro) where profession = '软件工程';
```



#### 覆盖索引

尽量使用覆盖索引，减少select *。覆盖索引是指查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到

| Extra                    | 含义                                                         |
| ------------------------ | ------------------------------------------------------------ |
| Using where; Using Index | 查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据 |
| Using index condition    | 查找使用了索引，但是需要回表查询数据                         |

![image-20250417170529672](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417170529672.png)



#### 前缀索引

当字段类型为字符串（varchar，text，longtext等）时，有时候需要索引很长的字符串，这会让索引变得很大，查询时，浪费大量的磁盘IO， 影响查询效率。此时可以只将字符串的一部分前缀，建立索引，这样可以大大节约索引空间，从而提高索引效率

**语法**

```mysql
create index idx_xxxx on table_name(column(n));
```

**前缀长度**

可以根据索引的选择性来决定，而选择性是指不重复的索引值（基数）和数据表的记录总数的比值，索引选择性越高则查询效率越高， 唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的

**前缀索引的查询流程**

![image-20250417170733070](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417170733070.png)



#### 单列索引与联合索引

- 单列索引：即一个索引只包含单个列

- 联合索引：即一个索引包含了多个列
- 在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引，而非单列索引

联合索引的结构示意图：

![image-20250418113136247](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418113136247.png)



### 索引设计原则

1. 针对于数据量较大，且查询比较频繁的表建立索引
2. 针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引
3. 尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高
4. 如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。
5. 尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高查询效率
6. 要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增删改的效率
7. 如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含NULL值时，它可以更好地确定哪个索引最有效地用于查询



# SQL优化

### 插入数据

如果我们需要一次性往数据库表中插入多条记录，可以从以下三个方面进行优化

方案一：

批量插入数据

```mysql
Insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry');
```

方案二：

手动控制事务

```mysql
start transaction;
insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry');
insert into tb_test values(4,'Tom'),(5,'Cat'),(6,'Jerry');
insert into tb_test values(7,'Tom'),(8,'Cat'),(9,'Jerry');
commit;
```

方案三：

主键顺序插入，性能要高于乱序插入



**大批量插入数据**

如果一次性需要插入大批量数据(比如: 几百万的记录)，使用insert语句插入性能较低，此时可以使

用MySQL数据库提供的load指令进行插入。操作如下：

![image-20250417210425975](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417210425975.png)

可以执行如下指令，将数据脚本文件中的数据加载到表结构中：

```mysql
-- 客户端连接服务端时，加上参数 -–local-infile
mysql –-local-infile -u root -p
-- 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关
set global local_infile = 1;
-- 执行load指令将准备好的数据，加载到表结构中
load data local infile '/root/sql1.log' into table tb_user fieldsterminated by ',' lines terminated by '\n' ;
```



### 主键优化

#### 数据组织方式

在InnoDB存储引擎中，表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表(index organized table IOT)

![image-20250417210610204](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417210610204.png)

行数据，都是存储在聚集索引的叶子节点上的，InnoDB的逻辑结构图：

![image-20250417101939331](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417101939331.png)

在InnoDB引擎中，数据行是记录在逻辑结构 page 页中的，而每一个页的大小是固定的，默认16K。

那也就意味着， 一个页中所存储的行也是有限的，如果插入的数据行row在该页存储不小，将会存储

到下一个页中，页与页之间会通过指针连接



#### 页分裂

页可以为空，也可以填充一半，也可以填充100%。每个页包含了2-N行数据(如果一行数据过大，会行溢出)，根据主键排列



主键顺序插入效果：

从磁盘中申请页， 主键顺序插入

![image-20250417210825305](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417210825305.png)

第一个页没有满，继续往第一页插入

![image-20250417210840025](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417210840025.png)

当第一个也写满之后，再写入第二个页，页与页之间会通过指针连接

![image-20250417210855542](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417210855542.png)

当第二页写满了，再往第三页写入

![image-20250417210909005](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417210909005.png)



主键乱序插入效果：

加入1#,2#页都已经写满了，存放了如图所示的数据

![image-20250417211000112](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211000112.png)

47所在的1#页，已经写满了，存储不了50对应的数据了。 那么此时会开辟一个新的页 3#

![image-20250417211036834](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211036834.png)

但是并不会直接将50存入3#页，而是会将1#页后一半的数据，移动到3#页，然后在3#页，插入50

![image-20250417211145995](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211145995.png)

![image-20250417211159585](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211159585.png)

移动数据，并插入id为50的数据之后，那么此时，这三个页之间的数据顺序是有问题的。 1#的下一个页，应该是3#， 3#的下一个页是2#。 所以，此时，需要重新设置链表指针

![image-20250417211234396](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211234396.png)

上述的这种现象，称之为 "页分裂"，是比较耗费性能的操作



#### 页合并

目前表中已有数据的索引结构(叶子节点)如下：

![image-20250417211333365](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211333365.png)

当我们对已有数据进行删除时，具体的效果如下:

当删除一行记录时，实际上记录并没有被物理删除，只是记录被标记（flaged）为删除并且它的空间变得允许被其他记录声明使用。

![image-20250417211352683](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211352683.png)

当我们继续删除2#的数据记录

![image-20250417211417161](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211417161.png)

当页中删除的记录达到 MERGE_THRESHOLD（默认为页的50%），InnoDB会开始寻找最靠近的页（前

或后）看看是否可以将两个页合并以优化空间使用

![](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211436576.png)

![image-20250417211449478](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211449478.png)

删除数据，并将页合并之后，再次插入新的数据21，则直接插入3#页

![image-20250417211521829](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250417211521829.png)

这个里面所发生的合并页的这个现象，就称之为 "页合并"

> [!NOTE]
>
> MERGE_THRESHOLD：合并页的阈值，可以自己设置，在创建表或者创建索引时指定



#### 索引设计原则

- 满足业务需求的情况下，尽量降低主键的长度
- 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键
- 尽量不要使用UUID做主键或者是其他自然主键，如身份证号
- 业务操作时，避免对主键的修改



### order by优化

| 方式           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| Using filesort | 通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区sort buffer中完成排序操作，所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序 |
| Using index    | 通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要额外排序，操作效率高 |



**优化原则**

- 根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则
- 尽量使用覆盖索引
- 多字段排序, 一个升序一个降序，此时需要注意联合索引在创建时的规则（ASC/DESC）
- 如果不可避免的出现filesort，大数据量排序时，可以适当增大排序缓冲区大小sort_buffer_size(默认256k)



升序/降序联合索引结构图示:

![image-20250418131940708](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418131940708.png)

![image-20250418131950909](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418131950909.png)



### group by优化

**优化原则**

- 在分组操作时，可以通过索引来提高效率
- 分组操作时，索引的使用也是满足最左前缀法则的



### limit优化

在数据量比较大时，如果进行limit分页查询，在查询时，越往后，分页查询效率越低

优化思路: 一般分页查询时，通过创建覆盖索引能够比较好地提高性能，可以通过覆盖索引加子查

询形式进行优化

```mysql
explain select * from tb_sku t , (select id from tb_sku order by id limit 2000000,10) a where t.id = a.id;
```



### count优化

- MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(\*) 的时候会直接返回这个数，效率很高； 但是如果是带条件的count，MyISAM也慢
- InnoDB 引擎就麻烦了，它执行 count(\*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。

如果说要大幅度提升InnoDB表的count效率，主要的优化思路：自己计数(可以借助于redis这样的数据库进行,但是如果是带条件的count又比较麻烦了)



**用法**

count（*）、count（主键）、count（字段）、count（数字）

| count用法   | 含义                                                         |
| ----------- | ------------------------------------------------------------ |
| count(主键) | InnoDB 引擎会遍历整张表，把每一行的 主键id 值都取出来，返回给服务层。服务层拿到主键后，直接按行进行累加(主键不可能为null) |
| count(字段) | 没有not null 约束 : InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，服务层判断是否为null，不为null，计数累加；有not null 约束：InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，直接按行进行累加 |
| count(数字) | InnoDB 引擎遍历整张表，但不取值。服务层对于返回的每一行，放一个数字“1”进去，直接按行进行累加 |
| count(*)    | InnoDB引擎并不会把全部字段取出来，而是专门做了优化，不取值，服务层直接按行进行累加 |

按照效率排序的话，count(字段) < count(主键 id) < count(1) ≈ count(\*)，所以尽量使用 count(\*)



### update优化

注意update语句执行时的注意事项

```mysql
update course set name = 'javaEE' where id = 1 ;
```

当我们在执行删除的SQL语句时，会锁定id为1这一行的数据，然后事务提交之后，行锁释放

但是当我们在执行如下SQL时

```mysql
update course set name = 'SpringBoot' where name = 'PHP' ;
```

当我们开启多个事务，在执行上述的SQL时，我们发现行锁升级为了表锁。 导致该update语句的性能

大大降低

> [!NOTE]
>
> InnoDB的行锁是针对索引加的锁，不是针对记录加的锁 ,并且该索引不能失效，否则会从行锁升级为表锁



# 视图

- 视图（View）是一种虚拟存在的表。视图中的数据并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的
- 通俗的讲，视图只保存了查询的SQL逻辑，不保存查询结果。所以我们在创建视图的时候，主要的工作就落在创建这条SQL查询语句上



### 语法

**创建**

```mysql
CREATE [OR REPLACE] VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]
```

**查询**

```mysql
查看创建视图语句：SHOW CREATE VIEW 视图名称;
查看视图数据：SELECT * FROM 视图名称 ...... ;
```

**修改**

```mysql
方式一：CREATE [OR REPLACE] VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH[ CASCADED | LOCAL ] CHECK OPTION ]
方式二：ALTER VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]
```

**删除**

```mysql
DROP VIEW [IF EXISTS] 视图名称 [,视图名称] ...
```



### 检查选项

当使用WITH CHECK OPTION子句创建视图时，MySQL会通过视图检查正在更改的每个行，例如 插入，更新，删除，以使其符合视图的定义。 MySQL允许基于另一个视图创建视图，它还会检查依赖视图中的规则以保持一致性。为了确定检查的范围，mysql提供了两个选项： CASCADED 和 LOCAL，默认值为 CASCADED 



**CASCADED**

级联

比如，v2视图是基于v1视图的，如果在v2视图创建的时候指定了检查选项为 cascaded，但是v1视图创建时未指定检查选项。 则在执行检查时，不仅会检查v2，还会级联检查v2的关联视图v1

![image-20250418155410892](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418155410892.png)

**LOCAL**

本地

比如，v2视图是基于v1视图的，如果在v2视图创建的时候指定了检查选项为 local ，但是v1视图创建时未指定检查选项。 则在执行检查时，只会检查v2，不会检查v2的关联视图v1

![image-20250418155522087](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418155522087.png)



### 视图的更新

要使视图可更新，视图中的行与基础表中的行之间必须存在一对一的关系。如果视图包含以下任何一项，则该视图不可更新：

- 聚合函数或窗口函数（SUM()、 MIN()、 MAX()、 COUNT()等）
- DISTINCT
- GROUP BY
- HAVING
- UNION 或者 UNION ALL



### 视图作用

1. 简单：视图不仅可以简化用户对数据的理解，也可以简化他们的操作。那些被经常使用的查询可以被定义为视图，从而使得用户不必为以后的操作每次指定全部的条件
2. 安全：数据库可以授权，但不能授权到数据库特定行和特定的列上。通过视图用户只能查询和修改他们所能见到的数据
3. 数据独立：视图可帮助用户屏蔽真实表结构变化带来的影响



# 存储过程

存储过程是==事先经过编译并存储在数据库中的一段 SQL 语句的集合==，调用存储过程可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是有好处的

存储过程思想上很简单，就是数据库 SQL 语言层面的代码封装与重用

![image-20250418160327568](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418160327568.png)

| 特点                         | 说明                                                         |
| ---------------------------- | ------------------------------------------------------------ |
| 封装，复用                   | 可以把某一业务SQL封装在存储过程中，需要用到的时候直接调用即可 |
| 可以接收参数，也可以返回数据 | 再存储过程中，可以传递参数，也可以接收返回值                 |
| 减少网络交互，效率提升       | 如果涉及到多条SQL，每执行一次都是一次网络传输。 而如果封装在存储过程中，我们只需要网络交互一次可能就可以了 |



### 语法

**创建**

```mysql
CREATE PROCEDURE 存储过程名称 ([ 参数列表 ])
BEGIN
	-- SQL语句
END ;
```

**调用**

```mysql
CALL 名称 ([ 参数 ]);
```

**查看**

```mysql
SELECT * FROM INFORMATION_SCHEMA.ROUTINES WHERE ROUTINE_SCHEMA = 'xxx'; -- 查询指定数据库的存储过程及状态信息
SHOW CREATE PROCEDURE 存储过程名称 ; -- 查询某个存储过程的定义
```

**删除**

```mysql
DROP PROCEDURE [ IF EXISTS ] 存储过程名称 ；
```

> [!NOTE]
>
> 在命令行中，执行创建存储过程的SQL时，需要通过关键字 delimiter 指定SQL语句的结束符



### 变量

#### 系统变量

系统变量 是MySQL服务器提供，不是用户定义的，属于服务器层面。分为全局变量（GLOBAL）、会话变量（SESSION）



**查看系统变量**

```mysql
SHOW [ SESSION | GLOBAL ] VARIABLES ; -- 查看所有系统变量
SHOW [ SESSION | GLOBAL ] VARIABLES LIKE '......'; -- 可以通过LIKE模糊匹配方式查找变量
SELECT @@[SESSION | GLOBAL] 系统变量名; -- 查看指定变量的值
```



**设置系统变量**

```mysql
SET [ SESSION | GLOBAL ] 系统变量名 = 值 ;
SET @@[SESSION | GLOBAL]系统变量名 = 值 ;
```

> [!NOTE]
>
> - 如果没有指定SESSION/GLOBAL，默认是SESSION，会话变量
> - mysql服务重新启动之后，所设置的全局参数会失效，要想不失效，可以在 /etc/my.cnf 中配置
> - 全局变量(GLOBAL): 全局变量针对于所有的会话
> - 会话变量(SESSION): 会话变量针对于单个会话，在另外一个会话窗口就不生效了



#### 用户定义变量

用户定义变量 是用户根据需要自己定义的变量，用户变量不用提前声明，在用的时候直接用 "@变量名" 使用就可以。其作用域为当前连接



**赋值**

```mysql
SET @var_name = expr [, @var_name = expr] ... ;
SET @var_name := expr [, @var_name := expr] ... ;
SELECT @var_name := expr [, @var_name := expr] ... ;
SELECT 字段名 INTO @var_name FROM 表名;
```



**使用**

```mysql
SELECT @var_name ;
```

> [!NOTE]
>
> 用户定义的变量无需对其进行声明或初始化，只不过获取到的值为NULL



#### 局部变量

局部变量是根据需要定义的在局部生效的变量，访问之前，需要DECLARE声明。可用作存储过程内的局部变量和输入参数，局部变量的范围是在其内声明的BEGIN ... END块



**声明**

```mysql
DECLARE 变量名 变量类型 [DEFAULT ... ] ;
```

变量类型就是数据库字段类型：INT、BIGINT、CHAR、VARCHAR、DATE、TIME等



**赋值**

```mysql
SET 变量名 = 值 ;
SET 变量名 := 值 ;
SELECT 字段名 INTO 变量名 FROM 表名 ... ;
```



### if

if 用于做条件判断，具体的语法结构为：

```mysql
IF 条件1 THEN
	.....
ELSEIF 条件2 THEN -- 可选
	.....
ELSE -- 可选
	.....
END IF;
```

在if条件判断的结构中，ELSE IF 结构可以有多个，也可以没有。 ELSE结构可以有，也可以没有



### 参数

参数的类型，主要分为以下三种：IN、OUT、INOUT。 具体的含义如下：

| 类型       | 含义                                         |
| ---------- | -------------------------------------------- |
| IN（默认） | 该类参数作为输入，也就是需要调用时传入值     |
| OUT        | 该类参数作为输出，也就是该参数可以作为返回值 |
| INOUT      | 既可以作为输入参数，也可以作为输出参数       |

**用法：**

```mysql
CREATE PROCEDURE 存储过程名称 ([ IN/OUT/INOUT 参数名 参数类型 ])
BEGIN
	-- SQL语句
END ;
```



**案例一**

根据传入参数score，判定当前分数对应的分数等级，并返回

```mysql
create procedure p4(in score int, out result varchar(10))
begin
	if score >= 85 then
		set result := '优秀';
	elseif score >= 60 then
		set result := '及格';
	else
		set result := '不及格';
	end if;
end;

-- 定义用户变量 @result来接收返回的数据, 用户变量可以不用声明
call p4(18, @result);

select @result;
```



**案例二**

将**传入**的200分制的分数，进行换算，换算成百分制，然后**返回**

```mysql
create procedure p5(inout score double)
begin
	set score := score * 0.5;
end;

set @score = 198;
call p5(@score);

select @score;
```



### case

语法1：

```mysql
-- 含义： 当case_value的值为 when_value1时，执行statement_list1，当值为 when_value2时，执行statement_list2， 否则就执行 statement_list
CASE case_value
	WHEN when_value1 THEN statement_list1
	[ WHEN when_value2 THEN statement_list2] ...
	[ ELSE statement_list ]
END CASE;
```



语法2：

```mysql
-- 含义： 当条件search_condition1成立时，执行statement_list1，当条件search_condition2成立时，执行statement_list2， 否则就执行 statement_list
CASE
	WHEN search_condition1 THEN statement_list1
	[WHEN search_condition2 THEN statement_list2] ...
	[ELSE statement_list]
END CASE;
```



### while

while 循环是有条件的循环控制语句。满足条件后，再执行循环体中的SQL语句。具体语法为：

```mysql
-- 先判定条件，如果条件为true，则执行逻辑，否则，不执行逻辑
WHILE 条件 DO
	SQL逻辑...
END WHILE;
```



### repeat

repeat是有条件的循环控制语句, 当满足until声明的条件的时候，则退出循环 。具体语法为：

```mysql
-- 先执行一次逻辑，然后判定UNTIL条件是否满足，如果满足，则退出。如果不满足，则继续下一次循环
REPEAT
	SQL逻辑...
	UNTIL 条件
END REPEAT;
```



### loop

LOOP 实现简单的循环，如果不在SQL逻辑中增加退出循环的条件，可以用其来实现简单的死循环

LOOP可以配合一下两个语句使用：

- LEAVE ：配合循环使用，退出循环
- ITERATE：必须用在循环中，作用是跳过当前循环剩下的语句，直接进入下一次循环

```mysql
[begin_label:] LOOP
	SQL逻辑...
END LOOP [end_label];
```

```mysql
LEAVE label; -- 退出指定标记的循环体
ITERATE label; -- 直接进入下一次循环
```

上述语法中出现的 begin_label，end_label，label 指的都是我们所自定义的标记



### 游标

游标（CURSOR）是用来存储查询结果集的数据类型 , 在存储过程和函数中可以使用游标对结果集进行循环的处理。游标的使用包括游标的声明、OPEN、FETCH 和 CLOSE，其语法分别如下

**声明游标**

```mysql
DECLARE 游标名称 CURSOR FOR 查询语句 ;
```

**打开游标**

```mysql
OPEN 游标名称 ;
```

**获取游标记录**

```mysql
FETCH 游标名称 INTO 变量 [, 变量 ] ;
```

**关闭游标**

```mysql
CLOSE 游标名称 ;
```



**案例**

根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名（name）和专业（profession），并将用户的姓名和专业插入到所创建的一张新表(id,name,profession)中

```mysql
-- 逻辑:
-- A. 声明游标, 存储查询结果集
-- B. 准备: 创建表结构
-- C. 开启游标
-- D. 获取游标中的记录
-- E. 插入数据到新表中
-- F. 关闭游标
create procedure p11(in uage int)
begin
	declare uname varchar(100);
	declare upro varchar(100);
	declare u_cursor cursor for select name,profession from tb_user where age <=uage;
	
	drop table if exists tb_user_pro;
	create table if not exists tb_user_pro(
		id int primary key auto_increment,
		name varchar(100),
		profession varchar(100)
	);
	
	open u_cursor;
	
	while true do
		fetch u_cursor into uname,upro;
		insert into tb_user_pro values (null, uname, upro);
	end while;
	
	close u_cursor;
end;

call p11(30);

```

上述的存储过程，最终我们在调用的过程中，会报错，之所以报错是因为上面的while循环中，并没有退出条件。当游标的数据集获取完毕之后，再次获取数据，就会报错，从而终止了程序的执行



### 条件处理程序

条件处理程序（Handler）可以用来定义在流程控制结构执行过程中遇到问题时相应的处理步骤



**语法**

```mysql
DECLARE handler_action HANDLER FOR condition_value [, condition_value]... statement ;

handler_action 的取值：
	CONTINUE: 继续执行当前程序
	EXIT: 终止执行当前程序
	
condition_value 的取值：
	SQLSTATE sqlstate_value: 状态码，如 02000
	
	SQLWARNING: 所有以01开头的SQLSTATE代码的简写
	NOT FOUND: 所有以02开头的SQLSTATE代码的简写
	SQLEXCEPTION: 所有没有被SQLWARNING 或 NOT FOUND捕获的SQLSTATE代码的简写
```

**示例**

```mysql
-- 逻辑:
-- A. 声明游标, 存储查询结果集
-- B. 准备: 创建表结构
-- C. 开启游标
-- D. 获取游标中的记录
-- E. 插入数据到新表中
-- F. 关闭游标
create procedure p11(in uage int)
begin
	declare uname varchar(100);
	declare upro varchar(100);
	declare u_cursor cursor for select name,profession from tb_user where age <=uage;
	-- 声明条件处理程序 ： 当SQL语句执行抛出的状态码为02000时，将关闭游标u_cursor，并退出
	declare exit handler for SQLSTATE '02000' close u_cursor;
	
	drop table if exists tb_user_pro;
	create table if not exists tb_user_pro(
		id int primary key auto_increment,
		name varchar(100),
		profession varchar(100)
	);
	
	open u_cursor;
	
	while true do
		fetch u_cursor into uname,upro;
		insert into tb_user_pro values (null, uname, upro);
	end while;
	
	close u_cursor;
end;

call p11(30);

```



# 存储函数

存储函数是有返回值的存储过程，存储函数的参数只能是IN类型的。具体语法如下：

```mysql
CREATE FUNCTION 存储函数名称 ([ 参数列表 ])
RETURNS type [characteristic ...]
BEGIN
	-- SQL语句
	RETURN ...;
END ;
```

characteristic说明：

- DETERMINISTIC：相同的输入参数总是产生相同的结果
- NO SQL ：不包含 SQL 语句
- READS SQL DATA：包含读取数据的语句，但不包含写入数据的语句

在mysql8.0版本中binlog默认是开启的，一旦开启了，mysql就要求在定义存储过程时，需要指定

characteristic特性，否则就会报如下错误：

![image-20250418183150597](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418183150597.png)



# 触发器

触发器是与表有关的数据库对象，指在insert/update/delete之前(BEFORE)或之后(AFTER)，触发并执行触发器中定义的SQL语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性, 日志记录 , 数据校验等操作 



使用别名OLD和NEW来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还只支持行级触发，不支持语句级触发。



| 触发器类型      | NEW和OLD                                                |
| --------------- | ------------------------------------------------------- |
| INSERT 型触发器 | NEW 表示将要或者已经新增的数据                          |
| UPDATE 型触发器 | OLD 表示修改之前的数据 , NEW 表示将要或已经修改后的数据 |
| DELETE 型触发器 | OLD 表示将要或者已经删除的数据                          |



## 语法

**创建**

```mysql
CREATE TRIGGER trigger_name
	BEFORE/AFTER INSERT/UPDATE/DELETE 
	ON tbl_name FOR EACH ROW -- 行级触发器
BEGIN
	trigger_stmt ;
END;
```

**查看**

```mysql
SHOW TRIGGERS ;
```

**删除**

```mysql
DROP TRIGGER [schema_name.]trigger_name ; -- 如果没有指定 schema_name，默认为当前数据库 
```



# 锁

锁是计算机协调多个进程或线程并发访问某一资源的机制。在数据库中，除传统的计算资源（CPU、RAM、I/O）的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤重要，也更加复杂



MySQL中的锁，按照锁的**粒度**分，分为以下三类：

全局锁：锁定数据库中的所有表

表级锁：每次操作锁住整张表

行级锁：每次操作锁住对应的行数据



按锁的**性质**分：

共享锁(S锁)：又称读锁，允许多个事务同时读取同一资源

排他锁(X锁)：又称写锁，独占资源，其他事务不能读写



### 全局锁

全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DML的写语句，DDL语句，已经更新操作的事务提交语句都将被阻塞

其典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据的完整性



#### 语法

加全局锁

```mysql
flush tables with read lock ;
```

数据备份

```bash
mysqldump -uroot –p1234 itcast > itcast.sql
```

释放锁

```mysql
unlock tables ;
```



#### 特点

数据库中加全局锁，是一个比较重的操作，存在以下问题：

- 如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆

- 如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志（binlog），会导致主从延迟



在InnoDB引擎中，我们可以在备份时加上参数 --single-transaction 参数来完成不加锁的一致性数据备份

```mysql
mysqldump --single-transaction -uroot –p123456 itcast > itcast.sql
```



### 表级锁

表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在MyISAM、InnoDB、BDB等存储引擎中。

对于表级锁，主要分为以下三类：

- 表锁

- 元数据锁（meta data lock，MDL）

- 意向锁



#### 表锁

对于表锁，分为两类：

- 表共享读锁（read lock）

- 表独占写锁（write lock）

**语法：**

- 加锁：lock tables 表名... read/write

- 释放锁：unlock tables 或者 客户端断开连接

**特点**

读锁：

![image-20250418192818073](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418192818073.png)

左侧为客户端一，对指定表加了读锁，不会影响右侧客户端二的读，但是会阻塞右侧客户端的写

写锁：

![image-20250418192903158](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418192903158.png)

左侧为客户端一，对指定表加了写锁，会阻塞右侧客户端的读和写



结论：读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞其他客户端的写



#### 元数据锁

meta data lock , 元数据锁，简写MDL

MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL锁主要作用是维护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。**为了避免DML与DDL冲突，保证读写的正确性**

这里的元数据，大家可以简单理解为就是一张表的表结构。 也就是说，某一张表涉及到未提交的事务时，是不能够修改这张表的表结构的

在MySQL5.5中引入了MDL，当对一张表==进行增删改查的时候，加MDL读锁(共享)；当对表结构进行变更操作的时候，加MDL写锁(排他)==



常见的SQL操作时，所添加的元数据锁：

| 对应SQL                                        | 锁类型                                  | 说明                                             |
| ---------------------------------------------- | --------------------------------------- | ------------------------------------------------ |
| lock tables xxx read / write                   | SHARED_READ_ONLY / SHARED_NO_READ_WRITE |                                                  |
| select 、select ... lock in share mode         | SHARED_READ                             | 与SHARED_READ、SHARED_WRITE兼容，与EXCLUSIVE互斥 |
| insert 、update、delete、select ... for update | SHARED_WRITE                            | 与SHARED_READ、SHARED_WRITE兼容，与EXCLUSIVE互斥 |
| alter table ...                                | EXCLUSIVE                               | 与其他的MDL都互斥                                |



#### 意向锁

为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查



假如没有意向锁，客户端一对表加了行锁后，客户端二如何给表加表锁呢，来通过示意图简单分析一下：

首先客户端一，开启一个事务，然后执行DML操作，在执行DML语句时，会对涉及到的行加行锁

![image-20250418194916697](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418194916697.png)

当客户端二，想对这张表加表锁时，会检查当前表是否有对应的行锁，如果没有，则添加表锁，此时就会从第一行数据，检查到最后一行数据，效率较低

![image-20250418194951748](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418194951748.png)

有了意向锁之后 :

客户端一，在执行DML操作时，会对涉及的行加行锁，同时也会对该表加上意向锁

![image-20250418195018477](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418195018477.png)

而其他客户端，在对这张表加表锁的时候，会根据该表上所加的意向锁来判定是否可以成功加表锁，而

不用逐行判断行锁情况了

![image-20250418195037907](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250418195037907.png)



**分类**

- 意向共享锁(IS): 由语句select ... lock in share mode添加 。 与表锁共享锁(read)兼容，与表锁排他锁(write)互斥
- 意向排他锁(IX): 由insert、update、delete、select...for update添加 。与表锁共享锁(read)及排他锁(write)都互斥，意向锁之间不会互斥



> [!NOTE]
>
> 一旦事务提交了，意向共享锁、意向排他锁，都会自动释放



### 行级锁

行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应用在InnoDB存储引擎中

InnoDB的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁。对于行级锁，主要分为以下三类：

**行锁（Record Lock）**：锁定单个行记录的锁，防止其他事务对此行进行update和delete。在RC、RR隔离级别下都支持

![image-20250419154641182](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419154641182.png)

**间隙锁（Gap Lock）**：锁定索引记录间隙（不含该记录），确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR隔离级别下都支持

![image-20250419154801671](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419154801671.png)

**临键锁（Next-Key Lock）**：行锁和间隙锁组合，同时锁住数据，并锁住数据前面的间隙Gap。在RR隔离级别下支持

![image-20250419154832734](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419154832734.png)



#### 行锁

InnoDB实现了以下两种类型的行锁：

- 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁

- 排他锁（X）：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他锁

两种行锁的兼容情况如下:

![image-20250419155006366](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419155006366.png)

常见的SQL语句，在执行时，所加的行锁如下：

| SQL                           | 行锁类型   | 说明                                    |
| ----------------------------- | ---------- | --------------------------------------- |
| INSERT ...                    | 排他锁     | 自动加锁                                |
| UPDATE ...                    | 排他锁     | 自动加锁                                |
| DELETE ...                    | 排他锁     | 自动加锁                                |
| SELECT（正常）                | 不加任何锁 |                                         |
| SELECT ... LOCK IN SHARE MODE | 共享锁     | 需要手动在SELECT之后加LOCK IN SHAREMODE |
| SELECT ... FOR UPDATE         | 排他锁     | 需要手动在SELECT之后加FOR UPDATE        |



默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读

- 针对唯一索引进行检索时，对已存在的记录进行等值匹配时，将会自动优化为行锁

- InnoDB的行锁是针对于索引加的锁，不通过索引条件检索数据，那么InnoDB将对表中的所有记录加锁，此时 就会升级为表锁



通过以下SQL，查看意向锁及行锁的加锁情况：

```mysql
select object_schema,object_name,index_name,lock_type,lock_mode,lock_data fromperformance_schema.data_locks;
```



#### 间隙锁&临键锁

默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读

- 索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁 

- 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁
- 索引上的范围查询(唯一索引)--会访问到不满足条件的第一个值为止



第二点分析：

InnoDB的B+树索引，叶子节点是有序的双向链表。 假如，我们要根据这个二级索引查询值为18的数据，并加上共享锁，我们是只锁定18这一行就可以了吗？ 并不是，因为是非唯一索引，这个结构中可能有多个18的存在，所以，在加锁时会继续往后找，找到一个不满足条件的值（当前案例中也就是29）。此时会对18加临键锁，并对29之前的间隙加锁

![image-20250419161034648](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419161034648.png)



> [!NOTE]
>
> 间隙锁唯一目的是防止其他事务插入间隙。间隙锁可以共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁



### 死锁

两个或多个事务互相持有对方需要的锁，导致所有事务都无法继续执行



### 查询锁

查看数据库中的**元数据锁**的情况：

```mysql
select object_type,object_schema,object_name,lock_type,lock_duration fromperformance_schema.metadata_locks ;
```

通过以下SQL，查看**意向锁及行锁**的加锁情况：

```mysql
select object_schema,object_name,index_name,lock_type,lock_mode,lock_data fromperformance_schema.data_locks;
```



# InnoDB引擎

### 逻辑存储结构

![image-20250419162016462](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419162016462.png)

**表空间**

表空间是InnoDB存储引擎逻辑结构的最高层， 如果用户启用了参数 innodb_file_per_table(在8.0版本中默认开启) ，则每张表都会有一个表空间（xxx.ibd），一个mysql实例可以对应多个表空间，用于存储记录、索引等数据

**段**

段，分为数据段（Leaf node segment）、索引段（Non-leaf node segment）、回滚段（Rollback segment），InnoDB是索引组织表，数据段就是B+树的叶子节点， 索引段即为B+树的非叶子节点。段用来管理多个Extent（区）

**区**

区，表空间的单元结构，每个区的大小为1M。 默认情况下， InnoDB存储引擎页大小为16K， 即一个区中一共有64个连续的页

**页**

页，是InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区

**行**

行，InnoDB 存储引擎数据是按行进行存放的

在行中，默认有两个隐藏字段：

- Trx_id：每次对某条记录进行改动时，都会把对应的事务id赋值给trx_id隐藏列

- Roll_pointer：每次对某条引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息



### 架构

MySQL5.5 版本开始，默认使用InnoDB存储引擎，它擅长事务处理，具有崩溃恢复特性，在日常开发中使用非常广泛。下面是InnoDB架构图，左侧为内存结构，右侧为磁盘结构

![image-20250419162749718](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419162749718.png)

#### 内存结构

**Buffer Pool**

InnoDB存储引擎基于磁盘文件存储，访问物理硬盘和在内存中进行访问，速度相差很大，为了尽可能弥补这两者之间的I/O效率的差值，就需要把经常使用的数据加载到缓冲池中，避免每次访问都进行磁盘I/O



在InnoDB的缓冲池中不仅缓存了索引页和数据页，还包含了undo页、插入缓存、自适应哈希索引以及InnoDB的锁信息等等



缓冲池 Buffer Pool，是主内存中的一个区域，里面可以缓存磁盘上经常操作的真实数据，在执行增删改查操作时，先操作缓冲池中的数据（若缓冲池没有数据，则从磁盘加载并缓存），然后再以一定频率刷新到磁盘，从而减少磁盘IO，加快处理速度



缓冲池以Page页为单位，底层采用链表数据结构管理Page。根据状态，将Page分为三种类型：

- free page：空闲page，未被使用。

- clean page：被使用page，数据没有被修改过。

- dirty page：脏页，被使用page，数据被修改过，也中数据与磁盘的数据产生了不一致。



在专用服务器上，通常将多达80％的物理内存分配给缓冲池 。参数设置： show variables like 'innodb_buffer_pool_size';



**Change Buffer**

Change Buffer，更改缓冲区（针对于非唯一二级索引页），在执行DML语句时，如果这些数据Page没有在Buffer Pool中，不会直接操作磁盘，而会将数据变更存在更改缓冲区 Change Buffer中，在未来数据被读取时，再将数据合并恢复到Buffer Pool中，再将合并后的数据刷新到磁盘中

![image-20250419163526054](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419163526054.png)

与聚集索引不同，二级索引通常是非唯一的，并且以相对随机的顺序插入二级索引。同样，删除和更新可能会影响索引树中不相邻的二级索引页，如果每一次都操作磁盘，会造成大量的磁盘IO。有了ChangeBuffer之后，我们可以在缓冲池中进行合并处理，减少磁盘IO



**Adaptive Hash Index**

自适应hash索引，用于优化对Buffer Pool数据的查询。MySQL的innoDB引擎中虽然没有直接支持hash索引，但是给我们提供了一个功能就是这个自适应hash索引。因为前面我们讲到过，hash索引在进行等值匹配时，一般性能是要高于B+树的，因为hash索引一般只需要一次IO即可，而B+树，可能需要几次匹配，所以hash索引的效率要高，但是hash索引又不适合做范围查询、模糊匹配等。InnoDB存储引擎会监控对表上各索引页的查询，如果观察到在特定的条件下hash索引可以提升速度，则建立hash索引，称之为自适应hash索引。

自适应哈希索引，无需人工干预，是系统根据情况自动完成。

参数： adaptive_hash_index



**Log Buffer**

Log Buffer：日志缓冲区，用来保存要写入到磁盘中的log日志数据（redo log 、undo log），默认大小为 16MB，日志缓冲区的日志会定期刷新到磁盘中。如果需要更新、插入或删除许多行的事务，增加日志缓冲区的大小可以节省磁盘 I/O。

参数:

innodb_log_buffer_size：缓冲区大小

innodb_flush_log_at_trx_commit：日志刷新到磁盘时机，取值主要包含以下三个：

1: 日志在每次事务提交时写入并刷新到磁盘，默认值

0: 每秒将日志写入并刷新到磁盘一次

2: 日志在每次事务提交后写入，并每秒刷新到磁盘一次



#### 磁盘结构

**System Tablespace**

系统表空间是更改缓冲区的存储区域。如果表是在系统表空间而不是每个表文件或通用表空间中创建的，它也可能包含表和索引数据。(在MySQL5.x版本中还包含InnoDB数据字典、undolog等)

参数：innodb_data_file_path



**File-Per-Table Tablespaces**

如果开启了innodb_file_per_table开关 ，则每个表的文件表空间包含单个InnoDB表的数据和索引 ，并存储在文件系统上的单个数据文件中。

开关参数：innodb_file_per_table ，该参数默认开启



**General Tablespaces**

通用表空间，需要通过 CREATE TABLESPACE 语法创建通用表空间，在创建表时，可以指定该表空间

**创建表空间**

```mysql
CREATE TABLESPACE ts_name ADD DATAFILE 'file_name' ENGINE = engine_name;
```

**创建表时指定表空间**

```mysql
CREATE TABLE xxx ... TABLESPACE ts_name;
```



**Undo Tablespaces**

撤销表空间，MySQL实例在初始化时会自动创建两个默认的undo表空间（初始大小16M），用于存储undo log日志



**Temporary Tablespaces**

InnoDB 使用会话临时表空间和全局临时表空间。存储用户创建的临时表等数据



**Doublewrite Buffer Files**

双写缓冲区，innoDB引擎将数据页从Buffer Pool刷新到磁盘前，先将数据页写入双写缓冲区文件中，便于系统异常时恢复数据



**Redo Log**

重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo logbuffer）以及重做日志文件（redo log）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中, 用于在刷新脏页到磁盘时,发生错误时, 进行数据恢复使用



#### 后台线程

![image-20250419165204110](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419165204110.png)

在InnoDB的后台线程中，分为4类，分别是：Master Thread 、IO Thread、Purge Thread、Page Cleaner Thread



**Master Thread**

核心后台线程，负责调度其他线程，还负责将缓冲池中的数据异步刷新到磁盘中, 保持数据的一致性，还包括脏页的刷新、合并插入缓存、undo页的回收



**IO Thread**

在InnoDB存储引擎中大量使用了AIO来处理IO请求, 这样可以极大地提高数据库的性能，而IOThread主要负责这些IO请求的回调

| 线程类型             | 默认个数 | 职责                         |
| -------------------- | -------- | ---------------------------- |
| Read thread          | 4        | 负责读操作                   |
| Write thread         | 4        | 负责写操作                   |
| Log thread           | 1        | 负责将日志缓冲区刷新到磁盘   |
| Insert buffer thread | 1        | 负责将写缓冲区内容刷新到磁盘 |

以通过以下的这条指令，查看到InnoDB的状态信息，其中就包含IO Thread信息

```mysql
show engine innodb status \G;
```



**Purge Thread**

主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收



**Page Cleaner Thread**

协助 Master Thread 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞



### 事务原理

#### 基础

事务 是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败

四大特性

- 原子性（Atomicity）：事务是不可分割的最小操作单元，要么全部成功，要么全部失败
- 一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态
- 隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行
- 持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的

其中的原子性、一致性、持久化，实际上是由InnoDB中的两份日志来保证的，一份是redo log日志，一份是undo log日志。 而隔离性是通过数据库的锁，加上MVCC来保证的

![image-20250419210931160](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419210931160.png)



#### redo log

重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的**持久性**

该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo logfile）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中, 用于在刷新脏页到磁盘,发生错误时, 进行数据恢复使用

在InnoDB引擎中的内存结构中，主要的内存区域就是缓冲池，在缓冲池中缓存了很多的数据页。 当我们在一个事务中，执行多个增删改的操作时，InnoDB引擎会先操作缓冲池中的数据，如果缓冲区没有对应的数据，会通过后台线程将磁盘中的数据加载出来，存放在缓冲区中，然后将缓冲池中的数据修改，修改后的数据页我们称为脏页。 而脏页则会在一定的时机，通过后台线程刷新到磁盘中，从而保证缓冲区与磁盘的数据一致。 而缓冲区的脏页数据并不是实时刷新的，而是一段时间之后将缓冲区的数据刷新到磁盘中，假如刷新到磁盘的过程出错了，而提示给用户事务提交成功，而数据却没有持久化下来，这就出现问题了，没有保证事务的持久性

![image-20250419211731627](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419211731627.png)

如何解决上述的问题呢？ 在InnoDB中提供了一份日志 redo log

![image-20250419211806572](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250419211806572.png)

有了redolog之后，当对缓冲区的数据进行增删改之后，会首先将操作的数据页的变化，记录在redolog buffer中。在事务提交时，会将redo log buffer中的数据刷新到redo log磁盘文件中。过一段时间之后，如果刷新缓冲区的脏页到磁盘时，发生错误，此时就可以借助于redo log进行数据恢复，这样就保证了事务的持久性。 而如果脏页成功刷新到磁盘 或 或者涉及到的数据已经落盘，此时redolog就没有作用了，就可以删除了，所以存在的两个redolog文件是循环写的

那为什么每一次提交事务，要刷新redo log 到磁盘中呢，而不是直接将buffer pool中的脏页刷新到磁盘呢 ?

因为在业务操作中，我们操作数据一般都是随机读写磁盘的，而不是顺序读写磁盘。 而redo log在往磁盘文件中写入数据，由于是日志文件，所以都是顺序写的。顺序写的效率，要远大于随机写。 这种先写日志的方式，称之为 WAL（Write-Ahead Logging）



#### undo log

回滚日志，用于记录数据被修改前的信息 , 作用包含两个 : 提供回滚(保证事务的原子性) 和MVCC(多版本并发控制)

undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚



Undo log销毁：undo log在事务执行时产生，事务提交时，并不会立即删除undo log，因为这些日志可能还用于MVCC

Undo log存储：undo log采用段的方式进行管理和记录，存放在前面介绍的 rollback segment回滚段中，内部包含1024个undo log segment



### MVCC

#### 基本概念

**当前读**

读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。对于我们日常的操作，如：select ... lock in share mode(共享锁)，select ...for update、update、insert、delete(排他锁)都是一种当前读

**快照读**

简单的select（不加锁）就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读

- Read Committed：每次select，都生成一个快照读

- Repeatable Read：开启事务后第一个select语句才是快照读的地方
- Serializable：快照读会退化为当前读

**MVCC**

全称 Multi-Version Concurrency Control，多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突，快照读为MySQL实现MVCC提供了一个非阻塞读功能。MVCC的具体实现，还需要依赖于数据库记录中的三个隐式字段、undo log日志、readView



#### 隐藏字段

| 隐藏字段    | 含义                                                         |
| ----------- | ------------------------------------------------------------ |
| DB_TRX_ID   | 最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID |
| DB_ROLL_PTR | 回滚指针，指向这条记录的上一个版本，用于配合undo log，指向上一个版本 |
| DB_ROW_ID   | 隐藏主键，如果表结构没有指定主键，将会生成该隐藏字段         |



#### undo log

- 回滚日志，在insert、update、delete的时候产生的便于数据回滚的日志

- 当insert的时候，产生的undo log日志只在回滚时需要，在事务提交后，可被立即删除

- 而update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读时也需要，不会立即被删除



**版本链**

有一张表原始数据为：

![image-20250420121126206](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420121126206.png)

DB_TRX_ID : 代表最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID，是自增的

DB_ROLL_PTR ： 由于这条数据是才插入的，没有被更新过，所以该字段值为null



然后，有四个并发事务同时在访问这张表

第一步

![image-20250420121216862](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420121216862.png)

当事务2执行第一条修改语句时，会记录undo log日志，记录数据变更之前的样子; 然后更新记录，并且记录本次操作的事务ID，回滚指针，回滚指针用来指定如果发生回滚，回滚到哪一个版本

![image-20250420121251956](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420121251956.png)

第二步

![image-20250420121427357](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420121427357.png)

当事务3执行第一条修改语句时，也会记录undo log日志，记录数据变更之前的样子; 然后更新记录，并且记录本次操作的事务ID，回滚指针

![image-20250420121442596](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420121442596.png)

第三步

![image-20250420121456512](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420121456512.png)

当事务4执行第一条修改语句时，也会记录undo log日志，记录数据变更之前的样子; 然后更新记录，并且记录本次操作的事务ID，回滚指针

![image-20250420121512419](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420121512419.png)

最终我们发现，不同事务或相同事务对同一条记录进行修改，会导致该记录的undolog生成一条记录版本链表，链表的头部是最新的旧记录，链表尾部是最早的旧记录



#### readview

ReadView（读视图）是==快照读 SQL执行时MVCC提取数据的依据==，记录并维护系统当前活跃的事务（未提交的）id

ReadView中包含了四个核心字段：

| 字段           | 含义                                                 |
| -------------- | ---------------------------------------------------- |
| m_ids          | 当前活跃的事务ID集合                                 |
| min_trx_id     | 最小活跃事务ID                                       |
| max_trx_id     | 预分配事务ID，当前最大事务ID+1（因为事务ID是自增的） |
| creator_trx_id | ReadView创建者的事务ID                               |

而在readview中就规定了版本链数据的访问规则：

trx_id 代表当前undolog版本链对应事务ID（DB_TRX_ID)

| 条件                               | 是否可以访问                              | 说明                                     |
| ---------------------------------- | ----------------------------------------- | ---------------------------------------- |
| trx_id == creator_trx_id           | 可以访问该版本                            | 成立，说明数据是当前这个事务更改的       |
| trx_id < min_trx_id                | 可以访问该版本                            | 成立，说明数据已经提交了                 |
| trx_id > max_trx_id                | 不可以访问该版本                          | 成立，说明该事务是在ReadView生成后才开启 |
| min_trx_id <= trx_id <= max_trx_id | 如果trx_id不在m_ids中，是可以访问该版本的 | 成立，说明数据已经提交                   |

不同的隔离级别，生成ReadView的时机不同：

- READ COMMITTED ：在事务中每一次执行快照读时生成ReadView
- REPEATABLE READ：仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView



#### 原理分析

##### RC隔离级别

RC隔离级别下，在事务中每一次执行快照读时生成ReadView

在事务5中，查询了两次id为30的记录，由于隔离级别为Read Committed，所以每一次进行快照读都会生成一个ReadView，那么两次生成的ReadView如下：

![image-20250420122239743](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420122239743.png)

那么这两次快照读在获取数据时，就需要根据所生成的ReadView以及ReadView的版本链访问规则，到undo log版本链中匹配数据，最终决定此次快照读返回的数据



第一次快照读具体的读取过程：

![image-20250420122505835](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420122505835.png)

在进行匹配时，会从undo log的版本链，从上到下进行挨个匹配：

![image-20250420122553367](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420122553367.png)

先匹配上图这条记录，这条记录对应的trx_id为4，也就是将4带入右侧的匹配规则（上上图）中。 ①不满足 ②不满足 ③不满足 ④也不满足 ，都不满足，则继续匹配undo log版本链的下一条

![image-20250420122657797](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420122657797.png)

再匹配第二条（如上图），这条记录对应的trx_id为3，也就是将3带入右侧的匹配规则中。①不满足 ②不满足 ③不满足 ④也不满足 ，都不满足，则继续匹配undo log版本链的下一条

![image-20250420122737722](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420122737722.png)

再匹配第三条（如上图），这条记录对应的trx_id为2，也就是将2带入右侧的匹配规则中。①不满足 ②满足 终止匹配，此次快照读，返回的数据就是版本链中记录的这条数据



看第二次快照读具体的读取过程：

![image-20250420123413816](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420123413816.png)

在进行匹配时，会从undo log的版本链，从上到下进行挨个匹配：

![image-20250420123251301](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420123251301.png)

先匹配上图这条记录，这条记录对应的trx_id为4，也就是将4带入右侧的匹配规则中。 ①不满足 ②不满足 ③不满足 ④也不满足 ，都不满足，则继续匹配undo log版本链的下一条

![image-20250420123339362](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420123339362.png)

再匹配第二条，这条记录对应的trx_id为3，也就是将3带入右侧的匹配规则中。①不满足 ②满足 。终止匹配，此次快照读，返回的数据就是版本链中记录的这条数据



##### RR隔离级别

RR隔离级别下，仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。 而RR 是可重复读，在一个事务中，执行两次相同的select语句，查询到的结果是一样的

![image-20250420123658180](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420123658180.png)

在RR隔离级别下，只是在事务中第一次快照读时生成ReadView，后续都是复用该ReadView，那么既然ReadView都一样， ReadView的版本链匹配规则也一样， 那么最终快照读返回的结果也是一样的



- MVCC的实现原理就是通过 InnoDB表的隐藏字段、UndoLog 版本链、ReadView来实现的

- 而MVCC + 锁，则实现了事务的隔离性。 而一致性则是由redolog 与 undolog保证

![image-20250420123817382](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420123817382.png)



# MySQL管理

### 系统数据库

Mysql数据库安装完成后，自带了一下四个数据库，具体作用如下：

| 数据库             | 含义                                                         |
| ------------------ | ------------------------------------------------------------ |
| mysql              | 存储MySQL服务器正常运行所需要的各种信息 （时区、主从、用户、权限等） |
| information_schema | 提供了访问数据库元数据的各种表和视图，包含数据库、表、字段类型及访问权限等 |
| performance_schema | 为MySQL服务器运行时状态提供了一个底层监控功能，主要用于收集数据库服务器性能参数 |
| sys                | 包含了一系列方便 DBA 和开发人员利用 performance_schema性能数据库进行性能调优和诊断的视图 |



### 常用工具

#### mysql

```mysql
语法 ：
	mysql [options] [database]
选项 ：
	-u, --user=name #指定用户名
	-p, --password[=name] #指定密码
	-h, --host=name #指定服务器IP或域名
	-P, --port=port #指定连接端口
	-e, --execute=name #执行SQL语句并退出
```



#### mysqladmin

mysqladmin 是一个执行管理操作的客户端程序。可以用它来检查服务器的配置和当前状态、创建并删除数据库等

```mysql
通过帮助文档查看选项：
	mysqladmin --help
语法:
	mysqladmin [options] command ...
选项:
	-u, --user=name #指定用户名
	-p, --password[=name] #指定密码
	-h, --host=name #指定服务器IP或域名
	-P, --port=port #指定连接端口
```



#### mysqlbinlog

由于服务器生成的二进制日志文件以二进制格式保存，所以如果想要检查这些文本的文本格式，就会使用到mysqlbinlog 日志管理工具

```mysql
语法 ：
	mysqlbinlog [options] log-files1 log-files2 ...
选项 ：
	-d, --database=name #指定数据库名称，只列出指定的数据库相关操作
    -o, --offset= #忽略掉日志中的前n行命令
    -r,--result-file=name #将输出的文本格式日志输出到指定文件
    -s, --short-form #显示简单格式， 省略掉一些信息
    --start-datatime=date1 --stop-datetime=date2 #指定日期间隔内的所有日志
    --start-position=pos1 --stop-position=pos2 #指定位置间隔内的所有日志
    -v #将行事件(数据变更)重构为SQL语句
    -vv #将行事件(数据变更)重构为SQL语句，并输出注释信息
```



#### mysqlshow

mysqlshow 客户端对象查找工具，用来很快地查找存在哪些数据库、数据库中的表、表中的列或者索引

```mysql
语法 ：
	mysqlshow [options] [db_name [table_name [col_name]]]
选项 ：
	--count 显示数据库及表的统计信息（数据库，表 均可以不指定）
	-i 显示指定数据库或者指定表的状态信息
```



#### mysqldump

mysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移。备份内容包含创建表，及插入表的SQL语句

```mysql
语法 ：
	mysqldump [options] db_name [tables] > [文件地址(文件名.sql)]
	mysqldump [options] --database/-B db1 [db2 db3...]
	mysqldump [options] --all-databases/-A
连接选项 ：
	-u, --user=name 指定用户名
	-p, --password[=name] 指定密码
	-h, --host=name 指定服务器ip或域名
	-P, --port=# 指定连接端口
输出选项：
	--add-drop-database 在每个数据库创建语句前加上 drop database 语句
	--add-drop-table 在每个表创建语句前加上 drop table 语句 , 默认开启 ; 不开启 (--skip-add-drop-table)
	-n, --no-create-db 不包含数据库的创建语句
	-t, --no-create-info 不包含数据表的创建语句
	-d --no-data 不包含数据
	-T, --tab=name 自动生成两个文件：一个.sql文件，创建表结构的语句；一个.txt文件，数据文件
```



#### mysqlimport

mysqlimport 是客户端数据导入工具，用来导入mysqldump 加 -T 参数后导出的文本文件

```mysql
语法 ：
	mysqlimport [options] db_name textfile1 [textfile2...]
```



#### source

如果需要导入sql文件,可以使用mysql中的source 指令

```mysql
source /root/xxxxx.sql
```



# 日志

### 错误日志

错误日志是 MySQL 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，建议首先查看此日志。

该日志是默认开启的，默认存放目录 /var/log/，默认的日志文件名为 mysqld.log 。查看日志位置：

```mysql
show variables like '%log_error%';
```



### 二进制日志

二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但不包括数据查询（SELECT、SHOW）语句

作用：①. 灾难时的数据恢复；②. MySQL的主从复制。在MySQL8版本中，默认二进制日志是开启着的，涉及到的参数如下：

```mysql
show variables like '%log_bin%';
```

参数说明：

- log_bin_basename：当前数据库服务器的binlog日志的基础名称(前缀)，具体的binlog文件名需要再该basename的基础上加上编号(编号从000001开始)

- log_bin_index：binlog的索引文件，里面记录了当前服务器关联的binlog文件有哪些



MySQL服务器中提供了多种格式来记录二进制日志，具体格式及特点如下：

| 日志格式  | 含义                                                         |
| --------- | ------------------------------------------------------------ |
| STATEMENT | 基于SQL语句的日志记录，记录的是SQL语句，对数据进行修改的SQL都会记录在日志文件中 |
| ROW       | 基于行的日志记录，记录的是每一行的数据变更。（默认）         |
| MIXED     | 混合了STATEMENT和ROW两种格式，默认采用STATEMENT，在某些特殊情况下会自动切换为ROW进行记录 |

```mysql
show variables like '%binlog_format%';
```

如果我们需要配置二进制日志的格式，只需要在 /etc/my.cnf 中配置 binlog_format 参数即可



**查看**

由于日志是以二进制方式存储的，不能直接读取，需要通过二进制日志查询工具[mysqlbinlog](####mysqlbinlog)来查看



**删除**

对于比较繁忙的业务系统，每天生成的binlog数据巨大，如果长时间不清除，将会占用大量磁盘空间。可以通过以下几种方式清理日志：

| 指令                                             | 含义                                                         |
| ------------------------------------------------ | ------------------------------------------------------------ |
| reset master                                     | 删除全部 binlog 日志，删除之后，日志编号，将从 binlog.000001重新开始 |
| purge master logs to 'binlog.*'                  | 删除 * 编号之前的所有日志                                    |
| purge master logs before 'yyyy-mm-dd hh24:mi:ss' | 删除日志为 "yyyy-mm-dd hh24:mi:ss" 之前产生的所有日志        |

也可以在mysql的配置文件中配置二进制日志的过期时间，设置了之后，二进制日志过期会自动删除

```mysql
show variables like '%binlog_expire_logs_seconds%';
```



### 查询日志

查询日志中记录了客户端的所有操作语句，而二进制日志不包含查询数据的SQL语句。默认情况下，查询日志是未开启的



如果需要开启查询日志，可以修改MySQL的配置文件 /etc/my.cnf 文件，添加如下内容：

```mysql
#该选项用来开启查询日志 ， 可选值 ： 0 或者 1 ； 0 代表关闭， 1 代表开启
general_log=1
#设置日志的文件名 ， 如果没有指定， 默认的文件名为 host_name.log
general_log_file=mysql_query.log
```

开启了查询日志之后，在MySQL的数据存放目录，也就是 /var/lib/mysql/ 目录下就会出现mysql_query.log 文件。之后所有的客户端的增删改查操作都会记录在该日志文件之中，长时间运行后，该日志文件将会非常大



### 慢查询日志

慢查询日志记录了所有执行时间超过参数 long_query_time 设置值并且扫描记录数不小于min_examined_row_limit 的所有的SQL语句的日志，默认未开启。long_query_time 默认为10 秒，最小为 0， 精度可以到微秒

如果需要开启慢查询日志，需要在MySQL的配置文件 /etc/my.cnf 中配置如下参数：

```mysql
#慢查询日志
slow_query_log=1
#执行时间参数
long_query_time=2
```

默认情况下，不会记录管理语句，也不会记录不使用索引进行查找的查询。可以使用log_slow_admin_statements和 更改此行为 log_queries_not_using_indexes

```mysql
#记录执行较慢的管理语句
log_slow_admin_statements =1
#记录执行较慢的未使用索引的语句
log_queries_not_using_indexes = 1
```

配置完毕之后，重启MySQL服务，查看慢日志文件中记录的信息/var/lib/mysql/\<hostname\>-slow.log



# 主从复制

### 概述

- 主从复制是指将主数据库的 DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步
- MySQL支持一台主库同时向多台从库进行复制， 从库同时也可以作为其他从服务器的主库，实现链状复制

![image-20250420154247135](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420154247135.png)

MySQL 复制的优点主要包含以下三个方面：

- 主库出现问题，可以快速切换到从库提供服务

- 实现读写分离，降低主库的访问压力

- 可以在从库中执行备份，以避免备份期间影响主库服务



### 原理

MySQL主从复制的核心就是 二进制日志，具体的过程如下：

![image-20250420154337135](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420154337135.png)

从上图来看，复制分成三步：

- Master 主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中
- 从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log 
- slave重做中继日志中的事件，将改变反映它自己的数据



### 搭建

![image-20250420154913819](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420154913819.png)

准备好两台服务器之后，在上述的两台服务器中分别安装好MySQL，并完成基础的初始化准备(安装、密码配置等操作)工作。 其中：

- 192.168.200.200 作为主服务器master

- 192.168.200.201 作为从服务器slave



#### 主库配置

修改配置文件 /etc/my.cnf

```mysql
#mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 232-1，默认为1
server-id=1
#是否只读,1 代表只读, 0 代表读写
read-only=0
#忽略的数据, 指不需要同步的数据库
#binlog-ignore-db=mysql
#指定同步的数据库
#binlog-do-db=db01
```

重启MySQL服务器

```bash
systemctl restart mysqld
```

登录mysql，创建远程连接的账号，并授予主从复制权限

```mysql
#创建itcast用户，并设置密码，该用户可在任意主机连接该MySQL服务
CREATE USER 'itcast'@'%' IDENTIFIED WITH mysql_native_password BY 'Root@123456';
#为 'itcast'@'%' 用户分配主从复制权限
GRANT REPLICATION SLAVE ON *.* TO 'itcast'@'%';
```

通过指令，查看二进制日志坐标

```mysql
show master status ;
```

![image-20250420155055780](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420155055780.png)

字段含义说明：

-  file : 从哪个日志文件开始推送日志文件

-  position ： 从哪个位置开始推送日志

-  binlog_ignore_db : 指定不需要同步的数据库



#### 从库配置

修改配置文件 /etc/my.cnf

```mysql
#mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 2^32-1，和主库不一样即可
server-id=2
#是否只读,1 代表只读, 0 代表读写
read-only=1
#管理员是否只读,1 代表只读, 0 代表读写
super-read-only=1
```

重新启动MySQL服务

```bash
systemctl restart mysqld
```

登录mysql，设置主库配置

```mysql
CHANGE REPLICATION SOURCE TO SOURCE_HOST='192.168.200.200', SOURCE_USER='itcast',SOURCE_PASSWORD='Root@123456', SOURCE_LOG_FILE='binlog.000004',SOURCE_LOG_POS=663;
```

上述是8.0.23中的语法。如果mysql是 8.0.23 之前的版本，执行如下SQL：

```mysql
CHANGE MASTER TO MASTER_HOST='192.168.200.200', MASTER_USER='itcast',MASTER_PASSWORD='Root@123456', MASTER_LOG_FILE='binlog.000004',MASTER_LOG_POS=663;
```

| 参数名          | 含义               | 8.0.23之前      |
| --------------- | ------------------ | --------------- |
| SOURCE_HOST     | 主库IP地址         | MASTER_HOST     |
| SOURCE_USER     | 连接主库的用户名   | MASTER_USER     |
| SOURCE_PASSWORD | 连接主库的密码     | MASTER_PASSWORD |
| SOURCE_LOG_FILE | binlog日志文件名   | MASTER_LOG_FILE |
| SOURCE_LOG_POS  | binlog日志文件位置 | MASTER_LOG_POS  |

开启同步操作

```mysql
start replica ; #8.0.22之后
start slave ; #8.0.22之前
```

查看主从同步状态

```mysql
show replica status ; #8.0.22之后
show slave status ; #8.0.22之前
```



# 分库分表

### 介绍

**问题分析**

![image-20250420161426808](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420161426808.png)

随着互联网及移动互联网的发展，应用系统的数据量也是成指数式增长，若采用单数据库进行数据存储，存在以下性能瓶颈：

- IO瓶颈：热点数据太多，数据库缓存不足，产生大量磁盘IO，效率较低。 请求数据太多，带宽不够，网络IO瓶颈
- CPU瓶颈：排序、分组、连接查询、聚合统计等SQL会耗费大量的CPU资源，请求数太多，CPU出现瓶颈



为了解决上述问题，我们需要对数据库进行分库分表处理

![image-20250420161507886](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420161507886.png)

分库分表的中心思想都是将数据分散存储，使得单一数据库/表的数据量变小来缓解单一数据库的性能问题，从而达到提升数据库性能的目的



**拆分策略**

分库分表的形式，主要是两种：垂直拆分和水平拆分。而拆分的粒度，一般又分为分库和分表，所以组成的拆分策略最终如下：

![image-20250420162308556](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420162308556.png)



**垂直拆分**

垂直分库：以表为依据，根据业务将不同表拆分到不同库中

![image-20250420162333707](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420162333707.png)

特点：

- 每个库的表结构都不一样

- 每个库的数据也不一样

- 所有库的并集是全量数据



垂直分表：以字段为依据，根据字段属性将不同字段拆分到不同表中

![image-20250420162502541](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420162502541.png)

特点：

- 每个表的结构都不一样

- 每个表的数据也不一样，一般通过一列（主键/外键）关联

- 所有表的并集是全量数据



**水平拆分**

水平分库：以字段为依据，按照一定策略，将一个库的数据拆分到多个库中

![image-20250420162629951](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420162629951.png)

特点：

- 每个库的表结构都一样

- 每个库的数据都不一样

- 所有库的并集是全量数据



水平分表：以字段为依据，按照一定策略，将一个表的数据拆分到多个表中

![image-20250420162721120](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420162721120.png)

特点：

- 每个表的表结构都一样

- 每个表的数据都不一样

- 所有表的并集是全量数据



### MyCat

#### 概述

**介绍**

- Mycat是开源的、活跃的、基于Java语言编写的MySQL数据库中间件。可以像使用mysql一样来使用mycat，对于开发人员来说根本感觉不到mycat的存在

- 开发人员只需要连接MyCat即可，而具体底层用到几台数据库，每一台数据库服务器里面存储了什么数据，都无需关心。 具体的分库分表的策略，只需要在MyCat中配置即可

![image-20250420162950894](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420162950894.png)

**下载**

> [!NOTE]
>
> [MyCat2](http://mycatone.top/)

**安装**

![image-20250420163718505](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420163718505.png)

**目录介绍**

![image-20250420163735141](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420163735141.png)

bin : 存放可执行文件，用于启动停止mycat

conf：存放mycat的配置文件

lib：存放mycat的项目依赖包（jar）

logs：存放mycat的日志文件

**概念介绍**

在MyCat的整体结构中，分为两个部分：上面的逻辑结构、下面的物理结构

![image-20250420163803434](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420163803434.png)

在MyCat的逻辑结构主要负责逻辑库、逻辑表、分片规则、分片节点等逻辑结构的处理，而具体的数据存储还是在物理结构，也就是数据库服务器中存储的



#### 入门

**需求**

由于 tb_order 表中数据量很大，磁盘IO及容量都到达了瓶颈，现在需要对 tb_order 表进行数据分片，分为三个数据节点，每一个节点主机位于不同的服务器上, 具体的结构，参考下图：

![image-20250420170633146](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420170633146.png)

**环境准备**

![image-20250420170653956](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420170653956.png)

**配置**

在分页配置（schema.xml）中配置逻辑库、逻辑表、数据节点、节点主机等相关信息。具体的配置如下：

```xml
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
   <schema name="DB01" checkSQLschema="true" sqlMaxLimit="100">
       <table name="TB_ORDER" dataNode="dn1,dn2,dn3" rule="auto-sharding-long"/>
   </schema>
   <dataNode name="dn1" dataHost="dhost1" database="db01" />
   <dataNode name="dn2" dataHost="dhost2" database="db01" />
   <dataNode name="dn3" dataHost="dhost3" database="db01" />
   <dataHost name="dhost1" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="jdbc" switchType="1" slaveThreshold="100">
       <heartbeat>select user()</heartbeat>
       <writeHost host="master" url="jdbc:mysql://192.168.200.210:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" />
   </dataHost>
   <dataHost name="dhost2" maxCon="1000" minCon="10" balance="0"
writeType="0" dbType="mysql" dbDriver="jdbc" switchType="1"
slaveThreshold="100">
       <heartbeat>select user()</heartbeat>
       <writeHost host="master" url="jdbc:mysql://192.168.200.213:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" />
   </dataHost>
   <dataHost name="dhost3" maxCon="1000" minCon="10" balance="0"
writeType="0" dbType="mysql" dbDriver="jdbc" switchType="1"
slaveThreshold="100">
       <heartbeat>select user()</heartbeat>
       <writeHost host="master" url="jdbc:mysql://192.168.200.214:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" />
   </dataHost>
</mycat:schema>
```

需要在server.xml中配置用户名、密码，以及用户的访问权限信息，具体的配置如下：

```xml
<user name="root" defaultAccount="true">
   <property name="password">123456</property>
   <property name="schemas">DB01</property>
   <!-- 表级 DML 权限设置 -->
   <!--
<privileges check="true"><schema name="DB01" dml="0110" ><table name="TB_ORDER" dml="1110"></table></schema></privileges>
-->
</user>
<user name="user">
   <property name="password">123456</property>
   <property name="schemas">DB01</property>
   <property name="readOnly">true</property>
</user>
```

上述的配置表示，定义了两个用户 root 和 user ，这两个用户都可以访问 DB01 这个逻辑库，访问密码都是123456，但是root用户访问DB01逻辑库，既可以读，又可以写，但是 user用户访问DB01逻辑库是只读的

**测试**

配置完毕后，先启动涉及到的3台分片服务器，然后启动MyCat服务器。切换到Mycat的安装目录，执行如下指令，启动Mycat：

```bash
#启动
bin/mycat start
#停止
bin/mycat stop
```

连接MyCat

```mysql
mysql -h 192.168.200.210 -P 8066 -uroot -p123456
```

在往 TB_ORDER 表中插入数据时：

如果id的值在1-500w之间，数据将会存储在第一个分片数据库中；如果id的值在500w-1000w之间，数据将会存储在第二个分片数据库中；如果id的值在1000w-1500w之间，数据将会存储在第三个分片数据库中；如果id的值超出1500w，在插入数据时，将会报错

这是由逻辑表配置时的一个参数 rule 决定的，而这个参数配置的就是分片规则



#### 配置

##### schema.xml

schema.xml 作为MyCat中最重要的配置文件之一 , 涵盖了MyCat的逻辑库 、 逻辑表 、 分片规则、分片节点及数据源的配置

![image-20250420212612443](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250420212612443.png)

主要包含三组标签：schema标签、datanode标签和datahost标签

| 标签     | 说明                                                         | 属性                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| schema   | 用于定义 MyCat实例中的**逻辑库** , 一个MyCat实例中, 可以有多个逻辑库 , 可以通过 schema 标签来划分不同的逻辑库。MyCat中的逻辑库的概念，等同于MySQL中的database概念, 需要操作某个逻辑库下的表时, 也需要切换逻辑库(use xxx) | name：指定自定义的逻辑库库名<br />checkSQLschema：在SQL语句操作时指定了数据库名称，执行时是否自动去除；true：自动去除，false：不自动去除<br />sqlMaxLimit：如果未指定limit进行查询，列表查询模式查询多少条记录 |
| table    | 用于定义了MyCat中逻辑库schema下的**逻辑表** , 所有需要拆分的表都需要在table标签中定义 | name：定义逻辑表表名，在该逻辑库下唯一<br />dataNode：定义逻辑表所属的dataNode，该属性需要与dataNode标签中name对应；多个dataNode逗号分隔<br />rule：分片规则的名字，分片规则名字是在rule.xml中定义的<br />primaryKey：逻辑表对应真实表的主键<br />type：逻辑表的类型，目前逻辑表只有全局表和普通表，如果未配置，就是普通表；全局表，配置为 global |
| datanode | 用于定义MyCat中的数据节点，也就是数据分片                    | name：定义数据节点名称<br />dataHost：数据库实例主机名称，引用自 dataHost 标签中name属性<br />database：定义分片所属数据库 |
| datahost | 该标签在MyCat逻辑库中作为底层标签存在, 直接定义了具体的数据库实例、读写分离、心跳语句 | name：唯一标识，供上层标签使用<br />maxCon/minCon：最大连接数/最小连接数<br />balance：负载均衡策略，取值 0,1,2,3<br />writeType：写操作分发方式（0：写操作转发到第一个writeHost，第一个挂了，切换到第二个；1：写操作随机分发到配置的writeHost）<br />dbDriver：数据库驱动，支持 native、jdbc |



##### rule.xml

rule.xml中定义所有拆分表的规则, 在使用过程中可以灵活的使用分片算法, 或者对同一个分片算法使用不同的参数, 它让分片过程可配置化。主要包含两类标签：tableRule、Function

![image-20250421163731703](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421163731703.png)



##### server.xml

server.xml配置文件包含了MyCat的系统配置信息，主要有两个重要的标签：system、user

**system标签**

![image-20250421163810372](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421163810372.png)

主要配置MyCat中的系统配置信息，对应的系统配置项及其含义，如下：

| 属性                | 取值  | 含义                                                         |
| ------------------- | ----- | ------------------------------------------------------------ |
| charset             | utf8  | 设置Mycat的字符集, 字符集需要与MySQL的字符集保持一致         |
| nonePasswordLogin   | 0,1   | 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户 |
| useHandshakeV10     | 0,1   | 使用该选项主要的目的是为了能够兼容高版本的jdbc驱动, 是否采用HandshakeV10Packet来与client进行通信, 1:是, 0:否 |
| useSqlStat          | 0,1   | 开启SQL实时统计, 1 为开启 , 0 为关闭 ;开启之后, MyCat会自动统计SQL语句的执行情况 ; mysql -h 127.0.0.1 -P 9066-u root -p 查看MyCat执行的SQL, 执行效率比较低的SQL , SQL的整体执行情况、读写比例等 ; show @@sql ; show@@sql.slow ; show @@sql.sum ; |
| useGlobleTableCheck | 0,1   | 是否开启全局表的一致性检测。1为开启 ，0为关闭                |
| sqlExecuteTimeout   | 1000  | SQL语句执行的超时时间 , 单位为 s ;                           |
| sequnceHandlerType  | 0,1,2 | 用来指定Mycat全局序列类型，0 为本地文件，1 为数据库方式，2 为时间戳列方式，默认使用本地文件方式，文件方式主要用于测试 |
| ...                 | ...   | ...                                                          |



**user标签**

配置MyCat中的用户、访问密码，以及用户针对于逻辑库、逻辑表的权限信息，具体的权限描述方式及配置说明如下：

![image-20250421164346781](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421164346781.png)



#### 分片

##### 垂直拆分

在业务系统中, 涉及以下表结构 ,但是由于用户与订单每天都会产生大量的数据, 单台服务器的数据存储及处理能力是有限的, 可以对数据库表进行拆分, 原有的数据库表如下

![image-20250421211104718](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421211104718.png)

现在考虑将其进行垂直分库操作，将商品相关的表拆分到一个数据库服务器，订单表拆分的一个数据库服务器，用户及省市区表拆分到一个服务器。最终结构如下：

![image-20250421211126131](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421211126131.png)

准备三台服务器，IP地址如图所示：

![image-20250421211144743](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421211144743.png)

并且在192.168.200.210，192.168.200.213, 192.168.200.214上面创建数据库shopping

配置schema.xml

```xml
<schema name="SHOPPING" checkSQLschema="true" sqlMaxLimit="100">
   <table name="tb_goods_base" dataNode="dn1" primaryKey="id" />
   <table name="tb_goods_brand" dataNode="dn1" primaryKey="id" />
   <table name="tb_goods_cat" dataNode="dn1" primaryKey="id" />
   <table name="tb_goods_desc" dataNode="dn1" primaryKey="goods_id" />
   <table name="tb_goods_item" dataNode="dn1" primaryKey="id" />
   <table name="tb_order_item" dataNode="dn2" primaryKey="id" />
   <table name="tb_order_master" dataNode="dn2" primaryKey="order_id" />
   <table name="tb_order_pay_log" dataNode="dn2" primaryKey="out_trade_no" />
   <table name="tb_user" dataNode="dn3" primaryKey="id" />
   <table name="tb_user_address" dataNode="dn3" primaryKey="id" />
   <table name="tb_areas_provinces" dataNode="dn3" primaryKey="id"/>
   <table name="tb_areas_city" dataNode="dn3" primaryKey="id"/>
   <table name="tb_areas_region" dataNode="dn3" primaryKey="id"/>
</schema>
<dataNode name="dn1" dataHost="dhost1" database="shopping" />
<dataNode name="dn2" dataHost="dhost2" database="shopping" />
<dataNode name="dn3" dataHost="dhost3" database="shopping" />
<dataHost name="dhost1" maxCon="1000" minCon="10" balance="0"
writeType="0" dbType="mysql" dbDriver="jdbc" switchType="1"
slaveThreshold="100">
   <heartbeat>select user()</heartbeat>
   <writeHost host="master" url="jdbc:mysql://192.168.200.210:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" />
</dataHost>
<dataHost name="dhost2" maxCon="1000" minCon="10" balance="0"
writeType="0" dbType="mysql" dbDriver="jdbc" switchType="1"
slaveThreshold="100">
   <heartbeat>select user()</heartbeat>
   <writeHost host="master" url="jdbc:mysql://192.168.200.213:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" />
</dataHost>
<dataHost name="dhost3" maxCon="1000" minCon="10" balance="0"
writeType="0" dbType="mysql" dbDriver="jdbc" switchType="1"
slaveThreshold="100">
   <heartbeat>select user()</heartbeat>
   <writeHost host="master" url="jdbc:mysql://192.168.200.214:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" />
</dataHost>
```

配置server.xml

```xml
<user name="root" defaultAccount="true">
   <property name="password">123456</property>
   <property name="schemas">SHOPPING</property>
   <!-- 表级 DML 权限设置 -->
   <!--
<privileges check="true"><schema name="DB01" dml="0110" ><table name="TB_ORDER" dml="1110"></table></schema></privileges>
-->
</user>
<user name="user">
   <property name="password">123456</property>
   <property name="schemas">SHOPPING</property>
   <property name="readOnly">true</property>
</user>
```

导入数据

![image-20250421212033031](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421212033031.png)

测试

```mysql
select ua.user_id, ua.contact, p.province, c.city, r.area , ua.address fromtb_user_address ua ,tb_areas_city c , tb_areas_provinces p ,tb_areas_region r where ua.province_id = p.provinceid and ua.city_id = c.cityid and ua.town_id = r.areaid ;
```

正常

```mysql
SELECT order_id , payment ,receiver, province , city , area FROM tb_order_master o, tb_areas_provinces p , tb_areas_city c , tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid ;
```

SQL语句执行报错。原因就是因为MyCat在执行该SQL语句时，需要往具体的数据库服务器中路由，而当前没有一个数据库服务器完全包含了订单以及省市区的表结构，造成SQL语句失败，报错

对于省、市、区/县表tb_areas_provinces , tb_areas_city , tb_areas_region，是属于数据字典表，在多个业务模块中都可能会遇到，可以将其设置为全局表，利于业务操作

修改配置

```xml
<table name="tb_areas_provinces" dataNode="dn1,dn2,dn3" primaryKey="id"
type="global"/>
<table name="tb_areas_city" dataNode="dn1,dn2,dn3" primaryKey="id"
type="global"/>
<table name="tb_areas_region" dataNode="dn1,dn2,dn3" primaryKey="id"
type="global"/>
```



##### 水平拆分

在业务系统中, 有一张表(日志表), 业务系统每天都会产生大量的日志数据 , 单台服务器的数据存储及处理能力是有限的, 可以对数据库表进行拆分

![image-20250421212246165](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421212246165.png)

准备三台服务器，具体的结构如下：

![image-20250421212303401](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421212303401.png)

并且，在三台数据库服务器中分表创建一个数据库itcast

配置schema.xml

```xml
<schema name="ITCAST" checkSQLschema="true" sqlMaxLimit="100">
   <table name="tb_log" dataNode="dn4,dn5,dn6" primaryKey="id" rule="mod-long" />
</schema>
<dataNode name="dn4" dataHost="dhost1" database="itcast" />
<dataNode name="dn5" dataHost="dhost2" database="itcast" />
<dataNode name="dn6" dataHost="dhost3" database="itcast" />
```

tb_log表最终落在3个节点中，分别是 dn4、dn5、dn6 ，而具体的数据分别存储在 dhost1、dhost2、dhost3的itcast数据库中

配置server.xml

配置root用户既可以访问 SHOPPING 逻辑库，又可以访问ITCAST逻辑库

```xml
<user name="root" defaultAccount="true">
   <property name="password">123456</property>
   <property name="schemas">SHOPPING,ITCAST</property>
   <!-- 表级 DML 权限设置 -->
   <!--
<privileges check="true"><schema name="DB01" dml="0110" ><table name="TB_ORDER" dml="1110"></table></schema></privileges>
-->
</user>
```



#### 分片规则

##### 范围分片

根据指定的字段及其配置的范围与数据节点的对应情况， 来决定该数据属于哪一个分片

![image-20250421214040896](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421214040896.png)

schema.xml逻辑表配置：

```xml
<table name="TB_ORDER" dataNode="dn1,dn2,dn3" rule="auto-sharding-long" />
```

schema.xml数据节点配置：

```xml
<dataNode name="dn1" dataHost="dhost1" database="db01" />
<dataNode name="dn2" dataHost="dhost2" database="db01" />
<dataNode name="dn3" dataHost="dhost3" database="db01" />
```

rule.xml分片规则配置：

```xml
<tableRule name="auto-sharding-long">
	<rule>
		<columns>id</columns>
		<algorithm>rang-long</algorithm>
	</rule>
</tableRule>
<function name="rang-long" class="io.mycat.route.function.AutoPartitionByLong">
	<property name="mapFile">autopartition-long.txt</property>
	<property name="defaultNode">0</property>
</function>
```

分片规则配置属性含义：

| 属性        | 描述                                                         |
| ----------- | ------------------------------------------------------------ |
| columns     | 标识将要分片的表字段                                         |
| algorithm   | 指定分片函数与function的对应关系                             |
| class       | 指定该分片算法对应的类                                       |
| mapFile     | 对应的外部配置文件                                           |
| type        | 默认值为0 ; 0 表示Integer , 1 表示String                     |
| defaultNode | 默认节点 默认节点的所用:枚举分片时,如果碰到不识别的枚举值, 就让它路由到默认节点 ; 如果没有默认值,碰到不识别的则报错 |

在rule.xml中配置分片规则时，关联了一个映射配置文件 autopartition-long.txt，该配置文件的配置如下：

```
# range start-end ,data node index
# K=1000,M=10000.
0-500M=0
500M-1000M=1
1000M-1500M=2
```

含义：0-500万之间的值，存储在0号数据节点(数据节点的索引从0开始) ； 500万-1000万之间的数据存储在1号数据节点 ； 1000万-1500万的数据节点存储在2号节点 ；

该分片规则，主要是针对于数字类型的字段适用。 在MyCat的入门程序中，我们使用的就是该分片规则



##### 取模分片

根据指定的字段值与节点数量进行求模运算，根据运算结果， 来决定该数据属于哪一个分片

![image-20250421214346605](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421214346605.png)

schema.xml逻辑表配置：

```xml
<table name="tb_log" dataNode="dn4,dn5,dn6" primaryKey="id" rule="mod-long" />
```

schema.xml数据节点配置：

```xml
<dataNode name="dn4" dataHost="dhost1" database="itcast" />
<dataNode name="dn5" dataHost="dhost2" database="itcast" />
<dataNode name="dn6" dataHost="dhost3" database="itcast" />
```

rule.xml分片规则配置：

```xml
<tableRule name="mod-long">
	<rule>
		<columns>id</columns>
		<algorithm>mod-long</algorithm>
	</rule>
</tableRule>
<function name="mod-long" class="io.mycat.route.function.PartitionByMod">
	<property name="count">3</property>
</function>
```

分片规则属性说明如下：

| 属性      | 描述                             |
| --------- | -------------------------------- |
| columns   | 标识将要分片的表字段             |
| algorithm | 指定分片函数与function的对应关系 |
| class     | 指定该分片算法对应的类           |
| count     | 数据节点的数量                   |

该分片规则，主要是针对于数字类型的字段适用。 在前面水平拆分的演示中，我们选择的就是取模分片



##### 一致性hash分片

所谓一致性哈希，相同的哈希因子计算值总是被划分到相同的分区表中，不会因为分区节点的增加而改变原来数据的分区位置，有效的解决了分布式数据的拓容问题

![image-20250421215437289](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421215437289.png)

schema.xml中逻辑表配置：

```xml
<!-- 一致性hash -->
<table name="tb_order" dataNode="dn4,dn5,dn6" rule="sharding-by-murmur" />
```

schema.xml中数据节点配置：

```xml
<dataNode name="dn4" dataHost="dhost1" database="itcast" />
<dataNode name="dn5" dataHost="dhost2" database="itcast" />
<dataNode name="dn6" dataHost="dhost3" database="itcast" />
```

rule.xml中分片规则配置：

```xml
<tableRule name="sharding-by-murmur">
	<rule>
		<columns>id</columns>
		<algorithm>murmur</algorithm>
	</rule>
</tableRule>
<function name="murmur" class="io.mycat.route.function.PartitionByMurmurHash">
	<property name="seed">0</property><!-- 默认是0 -->
	<property name="count">3</property>
	<property name="virtualBucketTimes">160</property>
</function>
```

分片规则属性含义：

| 属性               | 描述                                                         |
| ------------------ | ------------------------------------------------------------ |
| columns            | 标识将要分片的表字段                                         |
| algorithm          | 指定分片函数与function的对应关系                             |
| class              | 指定该分片算法对应的类                                       |
| seed               | 创建murmur_hash对象的种子，默认0                             |
| count              | 要分片的数据库节点数量，必须指定，否则没法分片               |
| virtualBucketTimes | 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍;virtualBucketTimes*count就是虚拟结点数量 ; |
| weightMapFile      | 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写，以从0开始到count-1的整数值也就是节点索引为key，以节点权重值为值。所有权重值必须是正整数，否则以1代替 |
| bucketMapPath      | 用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 |



##### 枚举分片

通过在配置文件中配置可能的枚举值, 指定数据分布到不同数据节点上, 本规则适用于按照省份、性别、状态拆分数据等业务

![image-20250421215907022](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250421215907022.png)

schema.xml中逻辑表配置：

```xml
<!-- 枚举 -->
<table name="tb_user" dataNode="dn4,dn5,dn6" rule="sharding-by-intfile-enumstatus"/>
```

schema.xml中数据节点配置：

```xml
<dataNode name="dn4" dataHost="dhost1" database="itcast" />
<dataNode name="dn5" dataHost="dhost2" database="itcast" />
<dataNode name="dn6" dataHost="dhost3" database="itcast" />
```

rule.xml中分片规则配置：

```xml
<tableRule name="sharding-by-intfile">
	<rule>
		<columns>sharding_id</columns>
		<algorithm>hash-int</algorithm>
    </rule>
</tableRule>
<!-- 自己增加 tableRule -->
<tableRule name="sharding-by-intfile-enumstatus">
	<rule>
		<columns>status</columns>
		<algorithm>hash-int</algorithm>
	</rule>
</tableRule>
<function name="hash-int" class="io.mycat.route.function.PartitionByFileMap">
	<property name="defaultNode">2</property>
	<property name="mapFile">partition-hash-int.txt</property>
</function>
```

partition-hash-int.txt ，内容如下 :

```
1=0
2=1
3=2
```

分片规则属性含义：

| 属性        | 描述                                                         |
| ----------- | ------------------------------------------------------------ |
| columns     | 标识将要分片的表字段                                         |
| algorithm   | 指定分片函数与function的对应关系                             |
| class       | 指定该分片算法对应的类                                       |
| mapFile     | 对应的外部配置文件                                           |
| type        | 默认值为0 ; 0 表示Integer , 1 表示String                     |
| defaultNode | 默认节点 ; 小于0 标识不设置默认节点 , 大于等于0代表设置默认节点 ;默认节点的所用:枚举分片时,如果碰到不识别的枚举值, 就让它路由到默认节点 ; 如果没有默认值,碰到不识别的则报错 |



##### 应用指定算法

运行阶段由应用自主决定路由到那个分片 , 直接根据字符子串（必须是数字）计算分片号

![image-20250422103555462](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422103555462.png)

schema.xml中逻辑表配置：

```xml
<!-- 应用指定算法 -->
<table name="tb_app" dataNode="dn4,dn5,dn6" rule="sharding-by-substring" />
```

schema.xml中数据节点配置：

```xml
<dataNode name="dn4" dataHost="dhost1" database="itcast" />
<dataNode name="dn5" dataHost="dhost2" database="itcast" />
<dataNode name="dn6" dataHost="dhost3" database="itcast" />
```

rule.xml中分片规则配置：

```xml
<tableRule name="sharding-by-substring">
	<rule>
		<columns>id</columns>
		<algorithm>sharding-by-substring</algorithm>
	</rule>
</tableRule>
<function name="sharding-by-substring"
class="io.mycat.route.function.PartitionDirectBySubString">
	<property name="startIndex">0</property> <!-- zero-based -->
	<property name="size">2</property>
	<property name="partitionCount">3</property>
	<property name="defaultPartition">0</property>
</function>
```

分片规则属性含义：

| 属性             | 含义                                                         |
| ---------------- | ------------------------------------------------------------ |
| columns          | 标识将要分片的表字段                                         |
| algorithm        | 指定分片函数与function的对应关系                             |
| class            | 指定该分片算法对应的类                                       |
| startIndex       | 字符子串起始索引                                             |
| size             | 字符长度                                                     |
| partitionCount   | 分区(分片)数量                                               |
| defaultPartition | 默认分片(在分片数量定义时, 字符标示的分片编号不在分片数量内时,使用默认分片) |



##### 固定分片hash算法

该算法类似于十进制的求模运算，但是为二进制的操作，例如，取 id 的二进制低 10 位 与1111111111 进行位 & 运算，位与运算最小值为 0000000000，最大值为1111111111，转换为十进制，也就是位于0-1023之间

![image-20250422103811513](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422103811513.png)

特点：

- 如果是求模，连续的值，分别分配到各个不同的分片；但是此算法会将连续的值可能分配到相同的分片，降低事务处理的难度

- 可以均匀分配，也可以非均匀分配

- 分片字段必须为数字类型



schema.xml中逻辑表配置：

```xml
<!-- 固定分片hash算法 -->
<table name="tb_longhash" dataNode="dn4,dn5,dn6" rule="sharding-by-long-hash" />
```

schema.xml中数据节点配置：

```xml
<dataNode name="dn4" dataHost="dhost1" database="itcast" />
<dataNode name="dn5" dataHost="dhost2" database="itcast" />
<dataNode name="dn6" dataHost="dhost3" database="itcast" />
```

rule.xml中分片规则配置：

```xml
<tableRule name="sharding-by-long-hash">
	<rule>
		<columns>id</columns>
		<algorithm>sharding-by-long-hash</algorithm>
	</rule>
</tableRule>
<!-- 分片总长度为1024，count与length数组长度必须一致； -->
<function name="sharding-by-long-hash"
class="io.mycat.route.function.PartitionByLong">
	<property name="partitionCount">2,1</property>
	<property name="partitionLength">256,512</property>
</function>
```

分片规则属性含义：

| 属性            | 描述                             |
| --------------- | -------------------------------- |
| columns         | 标识将要分片的表字段名           |
| algorithm       | 指定分片函数与function的对应关系 |
| class           | 指定该分片算法对应的类           |
| partitionCount  | 分片个数列表                     |
| partitionLength | 分片范围列表                     |

约束 :

- 分片长度 : 默认最大2^10 , 为 1024 

- count, length的数组长度必须是一致的 ;

以上分为三个分区:0-255,256-511,512-1023

![image-20250422104053375](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422104053375.png)



##### 字符串hash解析算法

截取字符串中的指定位置的子字符串, 进行hash算法， 算出分片

![image-20250422104112396](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422104112396.png)

schema.xml中逻辑表配置：

```xml
<!-- 字符串hash解析算法 -->
<table name="tb_strhash" dataNode="dn4,dn5" rule="sharding-by-stringhash" />
```

schema.xml中数据节点配置：

```xml
<dataNode name="dn4" dataHost="dhost1" database="itcast" />
<dataNode name="dn5" dataHost="dhost2" database="itcast" />
```

rule.xml中分片规则配置：

```xml
<tableRule name="sharding-by-stringhash">
	<rule>
		<columns>name</columns>
		<algorithm>sharding-by-stringhash</algorithm>
	</rule>
</tableRule>
<function name="sharding-by-stringhash"
class="io.mycat.route.function.PartitionByString">
	<property name="partitionLength">512</property> <!-- zero-based -->
	<property name="partitionCount">2</property>
	<property name="hashSlice">0:2</property>
</function>
```

分片规则属性含义：

| 属性            | 描述                                                         |
| --------------- | ------------------------------------------------------------ |
| columns         | 标识将要分片的表字段                                         |
| algorithm       | 指定分片函数与function的对应关系                             |
| class           | 指定该分片算法对应的类                                       |
| partitionLength | hash求模基数 ; length*count=1024 (出于性能考虑)              |
| partitionCount  | 分区数                                                       |
| hashSlice       | hash运算位 , 根据子字符串的hash运算 ; 0 代表 str.length(), -1 代表 str.length()-1 , 大于0只代表数字自身 ; 可以理解为substring（start，end），start为0则只表示0 |

![image-20250422104209934](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422104209934.png)



##### 按天分片算法

按照日期及对应的时间周期来分片

![image-20250422104312048](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422104312048.png)

schema.xml中逻辑表配置：

```xml
<!-- 按天分片 -->
<table name="tb_datepart" dataNode="dn4,dn5,dn6" rule="sharding-by-date" />
```

schema.xml中数据节点配置：

```xml
<dataNode name="dn4" dataHost="dhost1" database="itcast" />
<dataNode name="dn5" dataHost="dhost2" database="itcast" />
<dataNode name="dn6" dataHost="dhost3" database="itcast" />
```

rule.xml中分片规则配置：

```xml
<tableRule name="sharding-by-date">
	<rule>
		<columns>create_time</columns>
		<algorithm>sharding-by-date</algorithm>
	</rule>
</tableRule>
<function name="sharding-by-date" class="io.mycat.route.function.PartitionByDate">
		<property name="dateFormat">yyyy-MM-dd</property>
	<property name="sBeginDate">2022-01-01</property>
	<property name="sEndDate">2022-01-30</property>
	<property name="sPartionDay">10</property>
</function>
<!--从开始时间开始，每10天为一个分片，到达结束时间之后，会重复开始分片插入配置表的 dataNode 的分片，必须和分片规则数量一致，例如 2022-01-01 到 2022-12-31 ，每10天一个分片，一共需要37个分片-->
```

分片规则属性含义：

| 属性        | 描述                                                         |
| ----------- | ------------------------------------------------------------ |
| columns     | 标识将要分片的表字段                                         |
| algorithm   | 指定分片函数与function的对应关系                             |
| class       | 指定该分片算法对应的类                                       |
| dateFormat  | 日期格式                                                     |
| sBeginDate  | 开始日期                                                     |
| sEndDate    | 结束日期，如果配置了结束日期，则代码数据到达了这个日期的分片后，会重复从开始分片插入 |
| sPartionDay | 分区天数，默认值 10 ，从开始日期算起，每个10天一个分区       |



##### 自然月分片

使用场景为按照月份来分片, 每个自然月为一个分片

![image-20250422104520653](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422104520653.png)

schema.xml中逻辑表配置：

```xml
<!-- 按自然月分片 -->
<table name="tb_monthpart" dataNode="dn4,dn5,dn6" rule="sharding-by-month" />
```

schema.xml中数据节点配置：

```xml
<dataNode name="dn4" dataHost="dhost1" database="itcast" />
<dataNode name="dn5" dataHost="dhost2" database="itcast" />
<dataNode name="dn6" dataHost="dhost3" database="itcast" />
```

rule.xml中分片规则配置：

```xml
<tableRule name="sharding-by-month">
	<rule>
		<columns>create_time</columns>
		<algorithm>partbymonth</algorithm>
	</rule>
</tableRule>
<function name="partbymonth" class="io.mycat.route.function.PartitionByMonth">
	<property name="dateFormat">yyyy-MM-dd</property>
	<property name="sBeginDate">2022-01-01</property>
	<property name="sEndDate">2022-03-31</property>
</function>
<!--从开始时间开始，一个月为一个分片，到达结束时间之后，会重复开始分片插入配置表的 dataNode 的分片，必须和分片规则数量一致，例如 2022-01-01 到 2022-12-31 ，一共需要12个分片-->
```

分片规则属性含义：

| 属性       | 描述                                                         |
| ---------- | ------------------------------------------------------------ |
| columns    | 标识将要分片的表字段                                         |
| algorithm  | 指定分片函数与function的对应关系                             |
| class      | 指定该分片算法对应的类                                       |
| dateFormat | 日期格式                                                     |
| sBeginDate | 开始日期                                                     |
| sEndDate   | 结束日期，如果配置了结束日期，则代码数据到达了这个日期的分片后，会重复从开始分片插入 |



#### 管理及监控

##### 原理

![image-20250422110459430](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422110459430.png)

在MyCat中，当执行一条SQL语句时，MyCat需要进行SQL解析、分片分析、路由分析、读写分离分析等操作，最终经过一系列的分析决定将当前的SQL语句到底路由到那几个(或哪一个)节点数据库，数据库将数据执行完毕后，如果有返回的结果，则将结果返回给MyCat，最终还需要在MyCat中进行结果合并、聚合处理、排序处理、分页处理等操作，最终再将结果返回给客户端

而在MyCat的使用过程中，MyCat官方也提供了一个管理监控平台MyCat-Web（MyCat-eye）。Mycat-web 是 Mycat 可视化运维的管理和监控平台，弥补了 Mycat 在监控上的空白。帮 Mycat分担统计任务和配置管理任务。Mycat-web 引入了 ZooKeeper 作为配置中心，可以管理多个节点。Mycat-web 主要管理和监控 Mycat 的流量、连接、活动线程和内存等，具备 IP 白名单、邮件告警等模块，还可以统计 SQL 并分析慢 SQL 和高频 SQL 等。为优化 SQL 提供依据



##### 管理

Mycat默认开通2个端口，可以在server.xml中进行修改

- 8066 数据访问端口，即进行 DML 和 DDL 操作

- 9066 数据库管理端口，即 mycat 服务管理控制功能，用于管理mycat的整个集群状态

连接MyCat的管理控制台：

```mysql
mysql -h 192.168.200.210 -p 9066 -uroot -p123456
```

| 命令              | 含义                        |
| ----------------- | --------------------------- |
| show @@help       | 查看Mycat管理工具帮助文档   |
| show @@version    | 查看Mycat的版本             |
| reload @@config   | 重新加载Mycat的配置文件     |
| show @@datasource | 查看Mycat的数据源信息       |
| show @@datanode   | 查看MyCat现有的分片节点信息 |
| show @@threadpool | 查看Mycat的线程池信息       |
| show @@sql        | 查看执行的SQL               |
| show @@sql.sum    | 查看执行的SQL统计           |



##### MyCat-eye

Mycat-web(Mycat-eye)是对mycat-server提供监控服务，功能不局限于对mycat-server使用。他通过JDBC连接对Mycat、Mysql监控，监控远程服务器(目前仅限于linux系统)的cpu、内存、网络、磁盘

Mycat-eye运行过程中需要依赖zookeeper，因此需要先安装zookeeper



# 读写分离

读写分离,简单地说是把对数据库的读和写操作分开,以对应不同的数据库服务器。主数据库提供写操作，从数据库提供读操作，这样能有效地减轻单台数据库的压力。

通过MyCat即可轻易实现上述功能，不仅可以支持MySQL，也可以支持Oracle和SQL Server

![image-20250422110907699](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422110907699.png)



### 一主一从

MySQL的主从复制，是基于二进制日志（binlog）实现的

![image-20250422111003250](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422111003250.png)

参考[主从复制](#主从复制)



### 一主一从读写分离

MyCat控制后台数据库的读写分离和负载均衡由schema.xml文件datahost标签的balance属性控制

schema.xml配置

```xml
<!-- 配置逻辑库 -->
<schema name="ITCAST_RW" checkSQLschema="true" sqlMaxLimit="100" dataNode="dn7">
</schema>

<dataNode name="dn7" dataHost="dhost7" database="itcast" />

<dataHost name="dhost7" maxCon="1000" minCon="10" balance="1" writeType="0" dbType="mysql" dbDriver="jdbc" switchType="1" slaveThreshold="100">
	<heartbeat>select user()</heartbeat>
	<writeHost host="master1" url="jdbc:mysql://192.168.200.211:3306?useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8" user="root" password="1234" >
		<readHost host="slave1" url="jdbc:mysql://192.168.200.212:3306?useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8" user="root" password="1234" />
	</writeHost>
</dataHost>
```

![image-20250422111220912](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422111220912.png)

writeHost代表的是写操作对应的数据库，readHost代表的是读操作对应的数据库。 所以我们要想实现读写分离，就得配置writeHost关联的是主库，readHost关联的是从库

而仅仅配置好了writeHost以及readHost还不能完成读写分离，还需要配置一个非常重要的负责均衡的参数 balance，取值有4种，具体含义如下：

| 参数值 | 含义                                                         |
| ------ | ------------------------------------------------------------ |
| 0      | 不开启读写分离机制 , 所有读操作都发送到当前可用的writeHost上 |
| 1      | 全部的readHost 与 备用的writeHost 都参与select 语句的负载均衡（主要针对于双主双从模式） |
| 2      | 所有的读写操作都随机在writeHost , readHost上分发             |
| 3      | 所有的读请求随机分发到writeHost对应的readHost上执行, writeHost不负担读压力 |

所以，在一主一从模式的读写分离中，balance配置1或3都是可以完成读写分离的



server.xml配置

配置root用户可以访问SHOPPING、ITCAST 以及 ITCAST_RW逻辑库

```xml
<user name="root" defaultAccount="true">
	<property name="password">123456</property>
	<property name="schemas">SHOPPING,ITCAST,ITCAST_RW</property>
    
<!-- 表级 DML 权限设置 -->
<!--
	<privileges check="true">
		<schema name="DB01" dml="0110" >
			<table name="TB_ORDER" dml="1110"></table>
		</schema>
	</privileges>
-->
</user>
```



### 双主双从

一个主机 Master1 用于处理所有写请求，它的从机 Slave1 和另一台主机 Master2 还有它的从机 Slave2 负责所有读请求。当 Master1 主机宕机后，Master2 主机负责写请求，Master1 、Master2 互为备机。架构图如下:

![image-20250422121532574](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422121532574.png)

#### 主库配置

**Master1**

![image-20250422121543624](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422121543624.png)

修改配置文件 /etc/my.cnf

```
#mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 2^32-1，默认为1
server-id=1
#指定同步的数据库
binlog-do-db=db01
binlog-do-db=db02
binlog-do-db=db03
# 在作为从数据库的时候，有写入操作也要更新二进制日志文件
log-slave-updates
```

重启MySQL服务器

```bash
systemctl restart mysqld
```

创建账户并授权

```mysql
#创建itcast用户，并设置密码，该用户可在任意主机连接该MySQL服务
CREATE USER 'itcast'@'%' IDENTIFIED WITH mysql_native_password BY 'Root@123456';
#为 'itcast'@'%' 用户分配主从复制权限
GRANT REPLICATION SLAVE ON *.* TO 'itcast'@'%';
```



**Master2**

![image-20250422121759587](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422121759587.png)

修改配置文件 /etc/my.cnf

```
#mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 2^32-1，默认为1
server-id=3
#指定同步的数据库
binlog-do-db=db01
binlog-do-db=db02
binlog-do-db=db03
# 在作为从数据库的时候，有写入操作也要更新二进制日志文件
log-slave-updates
```

重启MySQL服务器

```bash
systemctl restart mysqld
```

创建账户并授权

```mysql
#创建itcast用户，并设置密码，该用户可在任意主机连接该MySQL服务
CREATE USER 'itcast'@'%' IDENTIFIED WITH mysql_native_password BY 'Root@123456';
#为 'itcast'@'%' 用户分配主从复制权限
GRANT REPLICATION SLAVE ON *.* TO 'itcast'@'%';
```



#### 从库配置

**Slave1**

![image-20250422121924615](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422121924615.png)

修改配置文件 /etc/my.cnf

```
#mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 232-1，默认为1
server-id=2
```

重启MySQL服务器

```bash
systemctl restart mysqld
```



**Slave2**

![image-20250422122010382](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422122010382.png)

修改配置文件 /etc/my.cnf

```
#mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 232-1，默认为1
server-id=4
```

重启MySQL服务器

```bash
systemctl restart mysqld
```



#### 从库关联主库

**两台从库配置关联的主库**

![image-20250422122141054](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422122141054.png)

在 slave1上执行

```mysql
CHANGE MASTER TO MASTER_HOST='192.168.200.211', MASTER_USER='itcast', MASTER_PASSWORD='Root@123456', MASTER_LOG_FILE='binlog.000002', MASTER_LOG_POS=663;
```

在 slave2上执行

```mysql
CHANGE MASTER TO MASTER_HOST='192.168.200.213', MASTER_USER='itcast', MASTER_PASSWORD='Root@123456', MASTER_LOG_FILE='binlog.000002', MASTER_LOG_POS=663;
```

启动两台从库主从复制，查看从库状态

```mysql
start slave;
show slave status \G;
```



**两台主库相互复制**

![image-20250422122313319](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422122313319.png)

在 Master1上执行

```mysql
CHANGE MASTER TO MASTER_HOST='192.168.200.213', MASTER_USER='itcast', MASTER_PASSWORD='Root@123456', MASTER_LOG_FILE='binlog.000002', MASTER_LOG_POS=663;
```

在 Master2上执行

```mysql
CHANGE MASTER TO MASTER_HOST='192.168.200.211', MASTER_USER='itcast', MASTER_PASSWORD='Root@123456', MASTER_LOG_FILE='binlog.000002', MASTER_LOG_POS=663;
```

启动两台从库主从复制，查看从库状态

```mysql
start slave;
show slave status \G;
```



### 双主双从读写分离

MyCat控制后台数据库的读写分离和负载均衡由schema.xml文件datahost标签的balance属性控制，通过writeType及switchType来完成失败自动切换的



**schema.xml**

配置逻辑库：

```xml
<schema name="ITCAST_RW2" checkSQLschema="true" sqlMaxLimit="100" dataNode="dn7">
</schema>
```

配置数据节点：

```xml
<dataNode name="dn7" dataHost="dhost7" database="db01" />
```

配置节点主机：

```xml
<dataHost name="dhost7" maxCon="1000" minCon="10" balance="1" writeType="0"
dbType="mysql" dbDriver="jdbc" switchType="1" slaveThreshold="100">
   <heartbeat>select user()</heartbeat>
   <writeHost host="master1" url="jdbc:mysql://192.168.200.211:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" >
       <readHost host="slave1" url="jdbc:mysql://192.168.200.212:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" />
   </writeHost>
   <writeHost host="master2" url="jdbc:mysql://192.168.200.213:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" >
       <readHost host="slave2" url="jdbc:mysql://192.168.200.214:3306?
useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8"
user="root" password="1234" />
   </writeHost>
</dataHost>
```

具体的对应情况如下：

![image-20250422122608191](https://picgo-zjp.oss-cn-shenzhen.aliyuncs.com/image-20250422122608191.png)

balance="1"

代表全部的 readHost 与 stand by writeHost 参与 select 语句的负载均衡，简单的说，当双主双从模式(M1->S1，M2->S2，并且 M1 与 M2 互为主备)，正常情况下，M2,S1,S2 都参与 select 语句的负载均衡 ;

writeType

0 : 写操作都转发到第1台writeHost, writeHost1挂了, 会切换到writeHost2上;

1 : 所有的写操作都随机地发送到配置的writeHost上 ;

switchType

-1 : 不自动切换

1 : 自动切换



**user.xml**

配置root用户也可以访问到逻辑库 ITCAST_RW2

```xml
<user name="root" defaultAccount="true">
   <property name="password">123456</property>
   <property name="schemas">SHOPPING,ITCAST,ITCAST_RW2</property>
   <!-- 表级 DML 权限设置 -->
   <!--
<privileges check="true"><schema name="DB01" dml="0110" ><table name="TB_ORDER" dml="1110"></table></schema></privileges>
-->
</user>
```
